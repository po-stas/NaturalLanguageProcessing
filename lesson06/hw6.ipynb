{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ДЗ #6 Классификация текста/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала, хотелось бы поработать над этой задачей с собственным датасетом.. На курсе \"ML в бизнесе\" делал курсовую по похожей теме, и, чтобы не разрабатывать sentiment analysis на уже порядком надоевшем IMDB - заскрапил базу отзывов с kinopoinsk.ru Там правда классификация на три класса - но это может даже интереснее. Вобщем с позволения - дз буду делать на этом датасете.. \n",
    "\n",
    "Сама курсовая, если вдруг интересно - тут:\n",
    "https://github.com/po-stas/review_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘datasets’: File exists\n",
      "--2021-04-16 13:41:49--  https://raw.githubusercontent.com/po-stas/review_analyzer/master/kinopoisk.csv\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7879478 (7,5M) [text/plain]\n",
      "Saving to: ‘./datasets/kinopoisk.csv’\n",
      "\n",
      "./datasets/kinopois 100%[===================>]   7,51M  2,94MB/s    in 2,6s    \n",
      "\n",
      "2021-04-16 13:41:53 (2,94 MB/s) - ‘./datasets/kinopoisk.csv’ saved [7879478/7879478]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Выкачиваем датасет\n",
    "!mkdir datasets\n",
    "!wget -O ./datasets/kinopoisk.csv https://raw.githubusercontent.com/po-stas/review_analyzer/master/kinopoisk.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n",
    "import textblob, string\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from stop_words import get_stop_words\n",
    "from string import punctuation\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>grade</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Гениальный студент Ягами Лайт с помощью тетрад...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Как известно, в СССР кино было делом государст...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>На фоне  многих других фильмов Марвел первые д...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  grade                                               text\n",
       "0           0    1.0  Гениальный студент Ягами Лайт с помощью тетрад...\n",
       "1           1    1.0  Как известно, в СССР кино было делом государст...\n",
       "2           2    1.0  На фоне  многих других фильмов Марвел первые д..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('datasets/kinopoisk.csv')\n",
    "dataset.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1710 entries, 0 to 1709\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   Unnamed: 0  1710 non-null   int64  \n",
      " 1   grade       1710 non-null   float64\n",
      " 2   text        1710 non-null   object \n",
      "dtypes: float64(1), int64(1), object(1)\n",
      "memory usage: 40.2+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    0.730409\n",
       "0.5    0.147953\n",
       "0.0    0.121637\n",
       "Name: grade, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Проверим распределение целевой переменной\n",
    "dataset['grade'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сильный дисбаланс классов в сторону положительных отзывов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для начала - бейзлайн какой-нибудь\n",
    "# Подготовим корпус"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmer = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_prep(token):\n",
    "    return lemmer.parse(''.join([char for char in token if char.isalpha()]).lower())[0].normal_form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_data = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_data['text'] = prep_data['text'].apply(lambda x: ' '.join([token_prep(token) for token in x.split()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    гениальный студент яга лайта с помощь тетрадь ...\n",
       "1    как известно в ссср кино быть дело государстве...\n",
       "2    на фон многий другой фильм марвести первый два...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_data.text.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(prep_data.text, prep_data.grade, \n",
    "                                                    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "838     обожать этот фильм у француз в начало х сохран...\n",
       "570     вот это уже большой похоже на южный парк есть ...\n",
       "873     второй картина гай ричать сохранить стилистиче...\n",
       "1557    крайне эффектный по свой атмосфера мрачный пуг...\n",
       "426     отличный фильм первый раз посмотреть он перед ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Векторизация\n",
    "tfvectorizer = TfidfVectorizer(ngram_range=(1, 4), analyzer='char')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1368, 74037)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tf = tfvectorizer.fit_transform(X_train)\n",
    "X_test_tf = tfvectorizer.transform(X_test)\n",
    "X_train_tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = le.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.2 s, sys: 20.6 s, total: 48.7 s\n",
      "Wall time: 3.54 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(random_state=42, max_iter=100)\n",
    "lr.fit(X_train_tf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tf = lr.predict(X_test_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7397660818713451"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, pred_tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вообще, наверное при такой несбалансированности классов - тут надо измерять ROC_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7395840828013317"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, lr.predict_proba(X_test_tf), multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Понятно.. Как-то примерно так и было в курсовой по Bussiness ML\n",
    "# Попробуем улучшить результат\n",
    "# Для начала - попробуем поиспользовать эмбеддинги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/postas/anaconda3/lib/python3.8/site-packages/gensim/similarities/__init__.py:15: UserWarning: The gensim.similarities.levenshtein submodule is disabled, because the optional Levenshtein package <https://pypi.org/project/python-Levenshtein/> is unavailable. Install Levenhstein (e.g. `pip install python-Levenshtein`) to suppress this warning.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_data_emb = dataset.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_data_emb['text'] = prep_data_emb['text'].apply(lambda x: [token_prep(token) for token in x.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_data_emb = prep_data_emb[prep_data_emb['text'].map(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Бьём на трейн-тест\n",
    "X_train_emb, X_test_emb, y_train_emb, y_test_emb = train_test_split(prep_data_emb.text, prep_data_emb.grade, \n",
    "                                                    test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Учим word2vec\n",
    "w2v = Word2Vec(X_train_emb, vector_size=1000, workers=16, window=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.28432840e-01,  1.47766834e-02,  4.15462814e-02,  7.27694556e-02,\n",
       "       -2.89174076e-03, -4.86377254e-02,  2.88003385e-02,  6.77371547e-02,\n",
       "       -8.74591153e-03, -1.31516310e-03,  6.34485781e-02,  6.57770736e-03,\n",
       "       -3.76283424e-03,  1.30032999e-02,  6.73472434e-02, -3.18785459e-02,\n",
       "        6.59571867e-03, -3.99084277e-02,  1.46304769e-02, -1.27435520e-01,\n",
       "        7.40185082e-02, -1.16130106e-01,  3.16223912e-02, -1.89955123e-02,\n",
       "        7.67104924e-02, -6.64684027e-02,  4.77185026e-02, -3.20074707e-02,\n",
       "       -1.85293511e-01,  4.65369560e-02,  7.22886696e-02, -6.63369372e-02,\n",
       "       -5.54299206e-02, -1.16584711e-02,  1.21556945e-01, -4.84180152e-02,\n",
       "        8.24535489e-02, -2.69778967e-02, -4.85867858e-02, -1.14521690e-01,\n",
       "       -5.64203598e-02,  3.73579599e-02, -1.23828031e-01,  1.43307760e-01,\n",
       "       -4.85709161e-02, -1.53342541e-02, -9.50107947e-02,  1.66504428e-01,\n",
       "       -7.48955905e-02,  5.44472001e-02,  2.55961884e-02,  1.96285732e-02,\n",
       "       -1.97715852e-02, -1.27031028e-01,  3.70853357e-02,  1.56864282e-02,\n",
       "        1.22050032e-01, -7.62304887e-02, -9.69534665e-02, -1.07111614e-02,\n",
       "       -1.22567236e-01, -3.99935097e-02, -1.29256159e-01,  3.61108338e-03,\n",
       "       -4.88284566e-02,  8.66329819e-02, -2.94360742e-02,  1.48477525e-01,\n",
       "       -3.74358497e-03, -4.10256200e-02,  1.03649132e-01, -3.94291207e-02,\n",
       "        6.82542548e-02, -9.51725468e-02,  3.21364030e-02,  4.39418629e-02,\n",
       "        2.26196628e-02, -3.30971517e-02, -6.97047391e-04,  3.19707859e-03,\n",
       "       -3.68897580e-02,  5.47823384e-02, -1.35956854e-01,  1.75707206e-01,\n",
       "       -1.45662069e-01,  6.36562258e-02, -2.35303342e-02,  3.19907665e-02,\n",
       "        4.18124720e-02,  4.50164527e-02,  5.72984815e-02,  4.16422114e-02,\n",
       "       -3.02826241e-02,  1.06802471e-01,  1.48317844e-01,  5.31382114e-02,\n",
       "        1.11748137e-01, -1.55721262e-01,  5.69984391e-02,  3.97203378e-02,\n",
       "        1.47904945e-03,  1.18904218e-01,  6.25836244e-03,  4.80605476e-02,\n",
       "       -1.31379096e-02,  1.32239759e-02,  1.18426755e-02,  6.08863868e-03,\n",
       "        2.69822218e-03, -1.26485378e-02, -3.01987771e-02, -1.13231771e-01,\n",
       "        6.98293597e-02,  1.21353425e-01,  1.05816416e-01, -9.05052666e-03,\n",
       "        1.29507333e-01, -1.36849225e-01,  4.43651341e-02, -1.40022114e-01,\n",
       "        3.32063157e-03, -2.06656866e-02,  8.39815810e-02, -1.70165841e-02,\n",
       "        1.47774210e-02, -4.52013090e-02, -2.10477412e-01,  1.13021120e-01,\n",
       "        1.41911337e-03,  1.01196624e-01,  8.96820799e-02,  4.98969741e-02,\n",
       "       -1.00878753e-01,  3.40453628e-03,  1.62967085e-03,  3.35998423e-02,\n",
       "        5.86449774e-03, -3.58563326e-02, -1.04644418e-01, -1.13559462e-01,\n",
       "        4.79084514e-02, -8.38861316e-02, -3.45354937e-02,  5.21624740e-03,\n",
       "        2.37233061e-02, -2.76051220e-02,  3.09164878e-02,  1.23974301e-01,\n",
       "        2.25841980e-02,  2.80702915e-02,  2.10177362e-01, -4.77973260e-02,\n",
       "       -4.03085761e-02,  1.02494486e-01, -2.01118320e-01,  1.01847827e-01,\n",
       "        1.48794562e-01,  6.80944175e-02, -5.01048341e-02,  7.24780411e-02,\n",
       "       -1.42427254e-03,  7.37413317e-02, -7.79785961e-02, -1.26492038e-01,\n",
       "       -5.14209121e-02,  1.37981653e-01,  1.75405622e-01,  9.34865773e-02,\n",
       "        4.44186758e-03,  2.22856820e-01,  3.40064503e-02,  1.06574476e-01,\n",
       "       -4.53479551e-02,  2.93538123e-02, -4.33861390e-02, -2.55331639e-02,\n",
       "       -1.27107725e-01, -1.97833981e-02, -6.82416707e-02,  4.14201505e-02,\n",
       "        5.58394641e-02, -1.07749561e-02,  3.17652933e-02,  1.28569687e-02,\n",
       "       -5.74136004e-02,  5.38137406e-02, -1.54855205e-02, -7.43758827e-02,\n",
       "        1.13880523e-01, -3.03105963e-03,  1.52810112e-01, -6.69806898e-02,\n",
       "       -7.41633214e-03, -1.38913551e-02,  1.04056537e-01,  4.78612632e-02,\n",
       "       -2.04488561e-02, -7.21582631e-03,  3.23381498e-02, -1.10204130e-01,\n",
       "       -4.77865264e-02,  1.32507114e-02,  1.46248594e-01,  1.43168243e-02,\n",
       "        6.27315417e-02, -1.36530166e-02, -1.52800113e-01,  1.85020752e-02,\n",
       "        2.00397205e-02,  1.34773375e-02,  3.34148854e-02, -3.49578401e-03,\n",
       "       -7.36884028e-02, -1.67943500e-02,  6.56918585e-02, -2.10807890e-01,\n",
       "       -9.55963135e-02, -3.07870526e-02, -1.56291410e-01, -8.63503963e-02,\n",
       "        9.82194915e-02,  6.00242727e-02,  8.70561451e-02,  1.43592749e-02,\n",
       "       -1.63506903e-02, -1.54661788e-02,  1.29844993e-01,  3.27600464e-02,\n",
       "        4.86336909e-02,  1.09861633e-02,  1.76518876e-02, -1.19982220e-01,\n",
       "        1.12531282e-01,  7.33751878e-02, -4.75475043e-02, -1.11551315e-01,\n",
       "       -5.94649278e-03, -1.15115024e-01,  1.25585169e-01,  5.71359415e-03,\n",
       "       -1.10981159e-01,  1.84454471e-02, -8.92623588e-02,  1.19080544e-01,\n",
       "        2.49956083e-02, -1.79127511e-02,  1.37274832e-01,  6.05329424e-02,\n",
       "       -6.74569309e-02,  4.52982523e-02,  3.41078974e-02, -8.12037587e-02,\n",
       "       -1.35346130e-01, -4.61329035e-02, -1.09350597e-02,  1.68344267e-02,\n",
       "        8.71550217e-02,  7.15779737e-02, -1.14541873e-01,  3.87779400e-02,\n",
       "       -1.01348922e-01,  4.26714979e-02, -1.47820897e-02,  2.24318672e-02,\n",
       "       -6.69486523e-02,  6.20647185e-02,  1.32516343e-02,  1.79597363e-01,\n",
       "       -1.88990995e-01,  5.27958274e-02,  1.43428901e-02,  4.80477326e-02,\n",
       "        5.36948908e-04,  5.27450778e-02, -1.05083592e-01,  1.12931110e-01,\n",
       "        6.31972328e-02, -1.05384260e-01, -1.22078501e-01,  1.50634632e-01,\n",
       "        3.43958996e-02,  4.76001613e-02, -1.06460623e-01, -6.90103769e-02,\n",
       "        9.49067548e-02,  1.42705385e-02,  1.07690636e-02, -6.88445792e-02,\n",
       "        4.27973419e-02,  4.63412851e-02, -1.40490651e-01,  1.34090886e-01,\n",
       "        6.42447248e-02,  1.03075886e-02,  1.14069894e-01, -3.69533487e-02,\n",
       "        1.62728935e-01, -6.11174246e-03,  6.31221160e-02, -1.47919552e-02,\n",
       "       -4.67624776e-02,  1.23384766e-01,  1.66450404e-02, -4.84222025e-02,\n",
       "       -4.88150381e-02, -8.79083201e-02, -5.36351651e-02,  8.27600807e-02,\n",
       "        9.39408466e-02, -1.53146356e-01, -5.51487617e-02, -1.52694076e-01,\n",
       "       -3.28508280e-02,  4.52514701e-02,  9.73848030e-02, -2.96266656e-02,\n",
       "        1.26324981e-01, -1.11874722e-01,  5.40266186e-02, -1.65140986e-01,\n",
       "        7.39736110e-02,  1.08825237e-01,  9.60951075e-02, -6.93603307e-02,\n",
       "       -6.85643554e-02, -1.20801114e-01, -5.41441292e-02, -1.67913809e-02,\n",
       "       -1.65325440e-02, -4.17685062e-02, -2.88116251e-04,  5.74355237e-02,\n",
       "       -2.75032315e-02, -2.11580843e-02,  3.19056697e-02, -1.94671527e-01,\n",
       "       -7.72501603e-02, -1.36268430e-03, -6.42397776e-02, -7.92445838e-02,\n",
       "        9.57080871e-02,  5.52792549e-02, -3.97466347e-02, -1.27494395e-01,\n",
       "       -3.97821283e-03,  6.99051470e-03, -2.67267734e-01, -5.00808619e-02,\n",
       "       -8.84375572e-02, -4.04586233e-02, -6.88231364e-02,  3.13727185e-02,\n",
       "       -1.27820879e-01,  1.82240620e-01,  2.83327159e-02,  2.57864863e-01,\n",
       "       -1.23247169e-01, -5.86907677e-02,  8.76788571e-02, -3.41932140e-02,\n",
       "       -1.28315940e-01,  1.39040500e-01, -4.40322608e-02,  2.59011053e-02,\n",
       "        4.91540022e-02, -1.76056232e-02,  7.55464360e-02, -2.12374359e-01,\n",
       "       -5.15082665e-02, -7.55048357e-03, -5.12479842e-02, -1.63941249e-01,\n",
       "       -2.00586870e-01, -2.64160056e-02,  8.49693315e-04,  2.20248774e-02,\n",
       "        3.56859900e-02,  1.04496956e-01,  1.47098273e-01,  9.04722810e-02,\n",
       "       -4.69721481e-02,  1.23399518e-01,  9.76345688e-02,  6.83635380e-03,\n",
       "        2.17576213e-02,  5.85962385e-02,  5.51073737e-02, -1.37756923e-02,\n",
       "        7.15278015e-02, -2.15217937e-02, -2.67586093e-02, -1.55039296e-01,\n",
       "       -1.84893012e-02, -9.89137217e-02,  1.67966392e-02, -7.96845406e-02,\n",
       "        1.01568982e-01, -2.72386265e-03, -1.24340147e-01,  4.69315946e-02,\n",
       "        1.08804457e-01,  1.02051318e-01, -2.17482429e-02, -1.70271069e-01,\n",
       "        6.85514957e-02, -7.50661567e-02,  2.81251073e-02,  1.19455419e-01,\n",
       "       -1.92236006e-02,  7.88290426e-02, -7.60725737e-02, -8.98241326e-02,\n",
       "       -6.31825253e-02, -2.99442094e-02, -1.24943471e-02, -1.14221144e-02,\n",
       "        7.32707381e-02,  8.46514404e-02,  1.84684753e-01, -1.45087630e-01,\n",
       "       -8.80354270e-02, -1.27544284e-01, -4.20395918e-02,  1.56730890e-01,\n",
       "       -3.73980217e-02, -1.40529826e-01, -7.28768557e-02,  6.21969029e-02,\n",
       "       -2.02587083e-01,  5.99449091e-02, -4.50404771e-02,  7.36654475e-02,\n",
       "       -7.88307190e-03,  3.88888479e-03,  1.24346189e-01,  1.04755461e-02,\n",
       "        7.87870809e-02,  3.33088338e-02,  7.88638294e-02,  7.32825473e-02,\n",
       "        1.22028254e-01,  1.80576053e-02,  4.25449982e-02,  1.44281015e-01,\n",
       "        3.69406611e-01,  6.89711422e-03,  1.02923721e-01, -6.83966577e-02,\n",
       "        6.51158839e-02, -1.14014791e-02,  9.77334902e-02,  3.86432209e-03,\n",
       "       -7.44640157e-02, -1.94576964e-01, -1.18294477e-01, -8.58147815e-02,\n",
       "       -1.57767385e-02, -1.61732867e-01,  2.28306293e-01,  6.73239306e-02,\n",
       "        2.60516293e-02,  1.26579151e-01, -8.79958123e-02,  1.73330873e-01,\n",
       "       -1.14506915e-01,  1.53344832e-02, -4.93197963e-02, -1.56480327e-01,\n",
       "        7.40334485e-03,  4.97066788e-02, -1.58581600e-01, -6.18533008e-02,\n",
       "        1.03291526e-01, -8.81127417e-02,  2.87487973e-02,  2.60718822e-01,\n",
       "        1.25958115e-01, -9.85460803e-02, -1.79988369e-01,  2.11618990e-02,\n",
       "       -1.37293905e-01, -1.46467388e-01, -2.92230956e-02,  2.35573113e-01,\n",
       "        4.01082970e-02,  7.76914805e-02,  7.92945474e-02,  1.58806652e-01,\n",
       "        3.99882644e-02, -8.84892344e-02, -4.57011349e-02, -3.04379058e-03,\n",
       "        1.42959774e-01, -4.31194678e-02, -5.02741635e-02,  4.95884754e-03,\n",
       "        2.75971442e-02, -1.17595509e-01, -1.40040621e-01,  2.65976544e-02,\n",
       "       -9.80914012e-03,  1.61026523e-01,  1.00068092e-01,  3.71401571e-02,\n",
       "       -1.06013454e-01, -1.97401717e-01,  6.40894547e-02,  3.10721725e-01,\n",
       "        1.43229574e-01,  1.74059197e-02, -8.63931924e-02,  7.40622953e-02,\n",
       "        7.64622688e-02, -6.92451224e-02,  2.50768233e-02, -2.16037005e-01,\n",
       "       -1.04907691e-01, -2.18124799e-02, -5.64871617e-02,  2.11482868e-01,\n",
       "        3.60382441e-03, -9.71492194e-03,  1.88031703e-01, -4.52927351e-02,\n",
       "        1.84200853e-02,  1.36686370e-01,  4.05594148e-02,  3.85497808e-02,\n",
       "       -8.09374675e-02, -9.78781059e-02, -2.83801239e-02,  8.42465833e-02,\n",
       "       -3.94694731e-02, -2.98400708e-02,  3.28219943e-02,  1.06679693e-01,\n",
       "       -5.96132129e-02, -1.88896969e-01, -4.35743928e-02, -8.60996917e-02,\n",
       "        1.35709541e-02, -1.06425598e-01, -8.41413289e-02, -2.47901883e-02,\n",
       "       -8.84196311e-02, -9.97540876e-02, -2.74188202e-02, -4.40998115e-02,\n",
       "        5.68828620e-02, -4.97602262e-02, -7.42971748e-02,  1.12373065e-02,\n",
       "       -5.14874272e-02, -1.23686202e-01,  2.58553959e-02, -2.04012357e-02,\n",
       "        7.59396926e-02,  2.98961233e-02,  5.05147390e-02,  8.20544511e-02,\n",
       "        1.73608854e-01,  2.18234044e-02,  3.51051539e-02,  5.59762456e-02,\n",
       "        1.07026519e-02,  9.78170708e-02, -5.22999018e-02, -1.11723216e-02,\n",
       "        5.73219657e-02,  9.88192298e-03, -1.73875898e-01,  2.45362837e-02,\n",
       "        6.41216815e-04,  4.65529831e-03,  4.49788198e-02,  7.48186186e-02,\n",
       "       -6.70139492e-02,  1.77190248e-02,  9.87091586e-02,  1.49208203e-01,\n",
       "        3.10554150e-02, -1.07959427e-01, -4.01421972e-02, -1.03559420e-02,\n",
       "       -5.86273111e-02, -8.61559249e-03, -2.58451365e-02,  3.16815525e-02,\n",
       "        9.47501976e-03,  9.12180617e-02, -5.36855496e-02, -1.24041382e-02,\n",
       "       -1.27789915e-01, -3.35183889e-02, -1.31632909e-02,  7.22245546e-03,\n",
       "       -4.27447706e-02,  1.05660632e-01,  7.41698369e-02,  9.13236737e-02,\n",
       "       -8.55102539e-02, -8.98174420e-02, -1.74144953e-01,  1.11544300e-02,\n",
       "        6.58262074e-02, -8.14732686e-02, -1.04864344e-01,  1.49218753e-01,\n",
       "       -8.07777047e-02,  8.70084986e-02, -8.83564651e-02, -3.32382023e-02,\n",
       "        7.43176835e-03,  1.29724294e-01, -1.34431675e-01,  5.45285158e-02,\n",
       "       -2.47549135e-02, -4.94280308e-02, -2.42644828e-02,  2.58181058e-02,\n",
       "       -9.19403415e-03, -5.56401946e-02,  1.55852214e-02, -8.08861181e-02,\n",
       "        5.29466197e-02,  3.59105766e-02, -1.26041725e-01, -1.05905406e-01,\n",
       "       -1.95569068e-01, -5.20239398e-02,  1.65838599e-01,  1.30270526e-01,\n",
       "       -1.45687340e-02, -7.40458220e-02,  3.84023562e-02,  1.67893916e-01,\n",
       "        6.22613318e-02,  4.69218791e-02, -1.14543609e-01, -2.23263204e-01,\n",
       "        2.35161949e-02, -7.53124058e-02,  8.19203109e-02, -8.97930115e-02,\n",
       "        4.83981110e-02,  1.00788787e-01, -7.41231665e-02, -1.16818145e-01,\n",
       "        1.54081896e-01,  9.97119918e-02, -4.28066477e-02,  4.54542600e-02,\n",
       "        4.71198000e-02,  8.66874754e-02,  3.00072003e-02, -7.37605691e-02,\n",
       "       -5.32491319e-02, -7.04316348e-02, -4.61836457e-02, -8.57008994e-02,\n",
       "        1.05456658e-01, -7.81678855e-02,  3.49879004e-02,  1.54173691e-02,\n",
       "       -1.74157042e-02, -1.21981034e-03,  1.29220828e-01,  2.84701549e-02,\n",
       "        4.19543311e-02, -2.78398115e-02,  7.16721863e-02,  8.43752250e-02,\n",
       "       -2.03201603e-02,  2.04701513e-01,  1.36635927e-02, -8.34704638e-02,\n",
       "        1.27266333e-01, -4.93273735e-02, -6.67218044e-02,  4.66693193e-02,\n",
       "       -4.63919304e-02, -2.78360061e-02,  3.22802812e-02,  2.91807833e-03,\n",
       "       -1.26480660e-03, -9.48863924e-02, -1.43413126e-01,  1.80983961e-01,\n",
       "       -1.30882695e-01, -1.55642163e-02,  1.63617488e-02, -2.47620158e-02,\n",
       "        4.63254973e-02, -2.56673526e-02,  9.66906827e-03, -2.72521805e-02,\n",
       "       -7.61145912e-03, -3.51350941e-02,  8.85912105e-02,  1.57459930e-01,\n",
       "        8.28087423e-03, -4.80739698e-02, -2.43808292e-02,  3.36455293e-02,\n",
       "       -2.43840739e-02,  8.10523182e-02,  1.57714427e-01, -2.86980886e-02,\n",
       "       -2.32039064e-01, -2.19755080e-02, -2.71527749e-02, -7.79183656e-02,\n",
       "       -1.55265763e-01, -6.24786764e-02, -6.25612214e-02,  4.19337564e-04,\n",
       "       -8.78278911e-03, -2.41420958e-02,  6.74354285e-02, -1.02078998e-02,\n",
       "        4.69532348e-02,  1.10958837e-01, -4.36570235e-02,  3.26708454e-04,\n",
       "        1.07986897e-01,  3.68751474e-02,  1.04295507e-01, -1.05529718e-01,\n",
       "        6.60118386e-02,  4.70836014e-02, -5.17760850e-02,  3.54287215e-02,\n",
       "       -2.96409540e-02, -5.55391014e-02, -6.00986034e-02,  8.66653118e-03,\n",
       "       -8.78452510e-02, -1.08476467e-01,  5.18067963e-02, -9.81474668e-02,\n",
       "        7.80669041e-03, -8.56604949e-02, -2.25318775e-01,  5.85463941e-02,\n",
       "       -7.86829367e-02, -9.92850289e-02, -1.06283069e-01,  1.96395312e-02,\n",
       "        9.38349888e-02,  9.44359303e-02,  2.28052717e-02, -1.62912697e-01,\n",
       "        9.66126770e-02, -3.07200775e-02, -9.39118639e-02,  1.28670990e-01,\n",
       "       -3.24120820e-02,  2.31974393e-01, -1.10073321e-01,  2.68253256e-02,\n",
       "       -4.17984976e-03, -2.44813226e-02, -1.93283230e-01,  2.72089150e-02,\n",
       "        7.65743405e-02, -9.58191007e-02, -1.55737162e-01, -4.24485318e-02,\n",
       "        1.45876296e-02, -1.12112418e-01, -9.61674079e-02,  2.73208208e-02,\n",
       "        2.27937743e-01, -1.20265886e-01, -8.58706683e-02, -6.66056126e-02,\n",
       "       -9.91954058e-02, -5.97320795e-02,  6.20928546e-03, -6.11500926e-02,\n",
       "       -3.47587392e-02, -6.99693337e-02, -1.57517176e-02, -6.42093122e-02,\n",
       "        2.11237594e-01, -1.67814165e-01,  2.01234035e-02,  6.11248277e-02,\n",
       "       -4.11481271e-03, -1.31631136e-01,  5.66276908e-02,  1.55094594e-01,\n",
       "       -5.20002134e-02,  3.21270898e-02, -6.93674572e-03,  9.12929475e-02,\n",
       "        9.21646692e-03, -2.45117530e-01,  8.12105089e-02, -7.89411068e-02,\n",
       "       -1.32790813e-03, -1.38433844e-01,  1.98005773e-02,  1.86413620e-02,\n",
       "        9.13915262e-02, -2.29251082e-03, -6.35845810e-02, -2.79815085e-02,\n",
       "       -6.34977296e-02,  1.20307826e-01,  1.35582620e-02, -9.92061570e-02,\n",
       "        3.44221778e-02,  8.71720910e-02,  3.70503892e-03, -8.56472272e-03,\n",
       "       -1.04148639e-02, -4.72057238e-02, -1.02755297e-02,  9.33791399e-02,\n",
       "        1.29123747e-01, -6.01442866e-02, -4.22835164e-03, -6.36561811e-02,\n",
       "        2.24160329e-02, -4.69747148e-02, -6.48090243e-02, -7.85098132e-03,\n",
       "       -1.54383190e-03,  2.81954836e-03,  5.52739315e-02,  3.09598111e-02,\n",
       "       -1.53133878e-02,  3.11847609e-02, -5.18681966e-02,  5.29465685e-03,\n",
       "       -6.08467236e-02,  1.35271326e-01,  1.37260687e-02, -1.33886173e-01,\n",
       "       -1.53030694e-01, -5.53820096e-02,  1.74071461e-01, -9.35080498e-02,\n",
       "        3.88812125e-02, -1.31792724e-01, -4.19189483e-02,  9.85151976e-02,\n",
       "        7.78015181e-02,  5.32489754e-02,  8.17143768e-02,  6.20295368e-02,\n",
       "       -6.40390441e-02,  3.89418229e-02, -4.30293940e-02, -1.25189070e-02,\n",
       "       -9.96703729e-02,  4.53242287e-02, -3.21922153e-02,  1.58906300e-02,\n",
       "        8.41492116e-02, -2.72028130e-02,  4.22626026e-02, -5.30688558e-03,\n",
       "       -9.94533226e-02, -1.58991925e-02, -9.27231833e-03,  2.97819786e-02,\n",
       "       -1.08893253e-01,  1.42871514e-01,  1.26308456e-01, -2.11638715e-02,\n",
       "        1.35454670e-01, -9.24332663e-02, -7.49830529e-02, -1.70164317e-01,\n",
       "       -7.73515180e-02,  1.96567755e-02, -1.13268934e-01, -1.09541856e-01,\n",
       "        7.66839385e-02, -1.61604509e-01,  1.05135947e-01, -2.68928297e-02,\n",
       "        2.19122116e-02, -3.74820009e-02,  1.47108538e-02,  6.47541881e-02,\n",
       "       -6.15700595e-02, -8.87816176e-02, -2.67816037e-02,  1.08420804e-01,\n",
       "       -1.15362694e-02,  1.89225245e-02,  9.30330083e-02,  1.73310965e-01,\n",
       "       -6.24263613e-03, -5.58494925e-02,  5.02029508e-02,  3.38670313e-02,\n",
       "       -9.27669555e-02,  6.13270211e-04, -1.35416225e-01, -1.05702765e-01,\n",
       "       -1.45205721e-01, -5.83769083e-02, -1.10455357e-01, -3.16191092e-02,\n",
       "        5.35623357e-02, -5.46595305e-02, -8.77402071e-03,  2.27386579e-02,\n",
       "       -9.40283909e-02, -9.26235765e-02,  5.19391745e-02,  1.16141483e-01,\n",
       "        1.40057117e-01, -5.21131754e-02,  5.50959781e-02,  5.27514750e-03,\n",
       "       -3.40377167e-02,  1.57606021e-01, -2.99038794e-02, -9.58955735e-02,\n",
       "       -2.38405215e-03,  1.15842588e-01, -5.29259704e-02, -3.96663435e-02,\n",
       "        9.95521527e-03, -1.23091646e-01,  2.78257243e-02, -2.79505667e-03,\n",
       "       -5.67638222e-03,  5.71914986e-02, -1.28112867e-01,  6.24294318e-02,\n",
       "       -6.33301511e-02, -3.22109535e-02, -8.38272721e-02,  1.12496214e-02,\n",
       "       -1.82285458e-02, -2.50738040e-02,  5.82283884e-02, -5.66481799e-02,\n",
       "       -8.66488728e-04,  6.07521124e-02,  1.48282258e-03,  1.07162505e-01,\n",
       "       -1.19414859e-01,  4.67656925e-02, -5.69760166e-02, -3.19369417e-03,\n",
       "       -1.23700984e-02, -3.12387422e-02,  6.50254413e-02,  2.45945230e-02,\n",
       "       -2.29993165e-02, -6.58258842e-03, -9.05674249e-02, -7.40097761e-02,\n",
       "        1.45122614e-02,  3.81354764e-02,  1.57463877e-03,  1.24553619e-02,\n",
       "       -1.15811646e-01, -1.20769106e-01,  1.84673612e-04, -1.36450171e-01,\n",
       "       -6.31464645e-02,  3.31541151e-02,  2.45460495e-02,  4.06925231e-02,\n",
       "        2.79468913e-02, -1.07845716e-01,  8.91934037e-02, -7.61304703e-03,\n",
       "        5.92537746e-02,  4.65535298e-02, -7.98121691e-02, -1.23647861e-01,\n",
       "        1.25460150e-02, -4.49924730e-02, -5.52875027e-02, -5.31654991e-03,\n",
       "        6.73820078e-02,  4.38645259e-02, -4.14403155e-02, -9.08202026e-03,\n",
       "        5.27425334e-02,  6.77229613e-02,  3.30985785e-02, -2.13734433e-02,\n",
       "        6.90532029e-02,  4.08917712e-03,  1.10004887e-01,  1.47885233e-02,\n",
       "       -1.16315961e-01, -1.06162086e-01, -5.32482751e-03, -8.29531401e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.wv['гениальный']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Что-то есть..\n",
    "# Прогоним это в LogReg. Для сравнения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_emb = X_train_emb.apply(lambda x: np.mean([w2v.wv[emb] for emb in x if emb in w2v.wv], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_emb = X_test_emb.apply(lambda x: np.mean([w2v.wv[emb] for emb in x if emb in w2v.wv], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Лейблы\n",
    "y_train_emb = le.fit_transform(y_train_emb)\n",
    "y_test_emb = le.fit_transform(y_test_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.18 s, sys: 1.62 s, total: 3.79 s\n",
      "Wall time: 252 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr.fit(np.stack(X_train_emb, axis=0), y_train_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6580411732594271"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test_emb, lr.predict_proba(np.stack(X_test_emb, axis=0)), multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# И снова, как-то тухло ))) Ембеддинги не рулят почему-то в моих экспериментах никак\n",
    "# Попробую еще размер вектора сделать длиннее"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Бьём на трейн-тест снова\n",
    "X_train_emb, X_test_emb, y_train_emb, y_test_emb = train_test_split(prep_data_emb.text, prep_data_emb.grade, \n",
    "                                                    test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Учим word2vec\n",
    "w2v = Word2Vec(X_train_emb, vector_size=5000, workers=16, window=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_emb = X_train_emb.apply(lambda x: np.mean([w2v.wv[emb] for emb in x if emb in w2v.wv], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_emb = X_test_emb.apply(lambda x: np.mean([w2v.wv[emb] for emb in x if emb in w2v.wv], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Лейблы\n",
    "y_train_emb = le.fit_transform(y_train_emb)\n",
    "y_test_emb = le.fit_transform(y_test_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.2 s, sys: 4.41 s, total: 20.6 s\n",
      "Wall time: 1.33 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, random_state=42)"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr.fit(np.stack(X_train_emb, axis=0), y_train_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6515286176198875"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test_emb, lr.predict_proba(np.stack(X_test_emb, axis=0)), multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6687790795330478"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Хуже\n",
    "# Попробуем другие параметры\n",
    "X_train_emb, X_test_emb, y_train_emb, y_test_emb = train_test_split(prep_data_emb.text, prep_data_emb.grade, \n",
    "                                                    test_size=0.2, random_state=42, shuffle=True)\n",
    "w2v = Word2Vec(X_train_emb, vector_size=500, workers=16, window=10)\n",
    "X_train_emb = X_train_emb.apply(lambda x: np.mean([w2v.wv[emb] for emb in x if emb in w2v.wv], axis=0))\n",
    "X_test_emb = X_test_emb.apply(lambda x: np.mean([w2v.wv[emb] for emb in x if emb in w2v.wv], axis=0))\n",
    "y_train_emb = le.fit_transform(y_train_emb)\n",
    "y_test_emb = le.fit_transform(y_test_emb)\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr.fit(np.stack(X_train_emb, axis=0), y_train_emb)\n",
    "roc_auc_score(y_test_emb, lr.predict_proba(np.stack(X_test_emb, axis=0)), multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6682629965566473"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_emb, X_test_emb, y_train_emb, y_test_emb = train_test_split(prep_data_emb.text, prep_data_emb.grade, \n",
    "                                                    test_size=0.2, random_state=42, shuffle=True)\n",
    "w2v = Word2Vec(X_train_emb, vector_size=600, workers=16, window=6)\n",
    "X_train_emb = X_train_emb.apply(lambda x: np.mean([w2v.wv[emb] for emb in x if emb in w2v.wv], axis=0))\n",
    "X_test_emb = X_test_emb.apply(lambda x: np.mean([w2v.wv[emb] for emb in x if emb in w2v.wv], axis=0))\n",
    "y_train_emb = le.fit_transform(y_train_emb)\n",
    "y_test_emb = le.fit_transform(y_test_emb)\n",
    "lr = LogisticRegression(random_state=42, max_iter=1000)\n",
    "lr.fit(np.stack(X_train_emb, axis=0), y_train_emb)\n",
    "roc_auc_score(y_test_emb, lr.predict_proba(np.stack(X_test_emb, axis=0)), multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вобщем до TFIDF ембеддингам как до луны )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Попробуем простые сеточки\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense, Dot, Embedding, Flatten, GlobalAveragePooling1D, Reshape\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from tensorflow.python.eager import context\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "tf.config.threading.set_inter_op_parallelism_threads(16)\n",
    "_ = tf.Variable([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(2048, activation='relu'),\n",
    "    Dense(512),\n",
    "    Dense(3, activation='softmax')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "22/22 [==============================] - 2s 80ms/step - loss: 0.8412 - accuracy: 0.7211 - val_loss: 0.7101 - val_accuracy: 0.7398\n",
      "Epoch 2/15\n",
      "22/22 [==============================] - 1s 36ms/step - loss: 0.5544 - accuracy: 0.7540 - val_loss: 0.7825 - val_accuracy: 0.7427\n",
      "Epoch 3/15\n",
      "22/22 [==============================] - 1s 37ms/step - loss: 0.1197 - accuracy: 0.9725 - val_loss: 0.8650 - val_accuracy: 0.7105\n",
      "Epoch 4/15\n",
      "22/22 [==============================] - 1s 35ms/step - loss: 0.0356 - accuracy: 0.9965 - val_loss: 1.6795 - val_accuracy: 0.7427\n",
      "Epoch 5/15\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.2637 - val_accuracy: 0.7661\n",
      "Epoch 6/15\n",
      "22/22 [==============================] - 1s 39ms/step - loss: 9.9566e-04 - accuracy: 1.0000 - val_loss: 1.3143 - val_accuracy: 0.7661\n",
      "Epoch 7/15\n",
      "22/22 [==============================] - 1s 36ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 1.3366 - val_accuracy: 0.7632\n",
      "Epoch 8/15\n",
      "22/22 [==============================] - 1s 36ms/step - loss: 5.9877e-04 - accuracy: 1.0000 - val_loss: 1.3604 - val_accuracy: 0.7632\n",
      "Epoch 9/15\n",
      "22/22 [==============================] - 1s 36ms/step - loss: 9.1900e-04 - accuracy: 1.0000 - val_loss: 1.3785 - val_accuracy: 0.7632\n",
      "Epoch 10/15\n",
      "22/22 [==============================] - 1s 36ms/step - loss: 7.7339e-04 - accuracy: 1.0000 - val_loss: 1.3888 - val_accuracy: 0.7632\n",
      "Epoch 11/15\n",
      "22/22 [==============================] - 1s 40ms/step - loss: 3.1091e-04 - accuracy: 1.0000 - val_loss: 1.4124 - val_accuracy: 0.7632\n",
      "Epoch 12/15\n",
      "22/22 [==============================] - 1s 36ms/step - loss: 5.8584e-04 - accuracy: 1.0000 - val_loss: 1.4143 - val_accuracy: 0.7632\n",
      "Epoch 13/15\n",
      "22/22 [==============================] - 1s 36ms/step - loss: 2.2555e-04 - accuracy: 1.0000 - val_loss: 1.4153 - val_accuracy: 0.7632\n",
      "Epoch 14/15\n",
      "22/22 [==============================] - 1s 36ms/step - loss: 2.3834e-04 - accuracy: 1.0000 - val_loss: 1.4538 - val_accuracy: 0.7632\n",
      "Epoch 15/15\n",
      "22/22 [==============================] - 1s 35ms/step - loss: 9.8782e-04 - accuracy: 1.0000 - val_loss: 1.4572 - val_accuracy: 0.7632\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2a0d19b700>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x = pd.DataFrame.sparse.from_spmatrix(X_train_tf),\n",
    "    y = y_train,\n",
    "    batch_size=64,\n",
    "    validation_data=(pd.DataFrame.sparse.from_spmatrix(X_test_tf), y_test),\n",
    "    epochs=15,\n",
    "    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-f3c8cf816222bbde\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-f3c8cf816222bbde\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/postas/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "# Нам нужен AUROC\n",
    "preds_nn = model.predict_proba(pd.DataFrame.sparse.from_spmatrix(X_test_tf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7662143474856812"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, preds_nn, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вобщем хоть и чуть-чуть выше - но все-же, ничего прорывного получить не удалось.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Еще есть вариант через сеточные эмбеддинги. Тоже интересно проверить."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_data_emb = dataset.copy()\n",
    "prep_data_emb['text'] = prep_data_emb['text'].apply(lambda x: [token_prep(token) for token in x.split()])\n",
    "prep_data_emb = prep_data_emb[prep_data_emb['text'].map(len) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_data_emb['joined'] = prep_data_emb.text.apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Бьём на трейн-тест\n",
    "X_train_emb, X_test_emb, y_train_emb, y_test_emb = train_test_split(prep_data_emb.joined, prep_data_emb.grade, \n",
    "                                                    test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "568     для свой произведение василь быков брать сюжет...\n",
       "1327    с точка зрение общий впечатление от сериал  я ...\n",
       "1062    в день премьера в близкий кинотеатр всё билет ...\n",
       "115     на удивление картина не разочаровать и для сто...\n",
       "454     человек всегда обычно ждать наступление новый ...\n",
       "Name: joined, dtype: object"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_emb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# лейблы не закодированы\n",
    "le = LabelEncoder()\n",
    "y_train_emb = le.fit_transform(y_train_emb)\n",
    "y_test_emb = le.transform(y_test_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Измерить количество слов в рецензии\n",
    "prep_data_emb['word_count'] = prep_data_emb.text.apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_data_emb.word_count.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1025"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_data_emb.word_count.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375.03861907548276"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_data_emb.word_count.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "316.0"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_data_emb.word_count.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "520.0"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_data_emb.word_count.quantile(0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ну, пусть будет длина сиквенса 500 слов\n",
    "# Еще, не вредно будет понять размер словаря.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "for row in X_train_emb:\n",
    "    for word in row.split():\n",
    "        if word not in vocab:\n",
    "            vocab.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30215"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вобщем....\n",
    "seq_len = 500\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer = TextVectorization(\n",
    "    standardize=None,  # Уже весь препроцессинг сделан\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    output_sequence_length=seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorize_layer.adapt(X_train_emb.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim=500\n",
    "\n",
    "model = Sequential([\n",
    "  vectorize_layer,\n",
    "  Embedding(vocab_size, embedding_dim, name=\"embedding\"),\n",
    "  GlobalAveragePooling1D(),\n",
    "  Dense(32, activation='relu'),\n",
    "  Dense(3, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "22/22 [==============================] - 3s 126ms/step - loss: 1.0355 - accuracy: 0.6695 - val_loss: 0.8069 - val_accuracy: 0.7368\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 3s 117ms/step - loss: 0.7845 - accuracy: 0.7335 - val_loss: 0.7585 - val_accuracy: 0.7368\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.7802 - accuracy: 0.7169 - val_loss: 0.7444 - val_accuracy: 0.7368\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 3s 114ms/step - loss: 0.7232 - accuracy: 0.7355 - val_loss: 0.7361 - val_accuracy: 0.7368\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.7241 - accuracy: 0.7191 - val_loss: 0.7247 - val_accuracy: 0.7368\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.6720 - accuracy: 0.7304 - val_loss: 0.7098 - val_accuracy: 0.7368\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.6384 - accuracy: 0.7153 - val_loss: 0.6872 - val_accuracy: 0.7368\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 3s 116ms/step - loss: 0.5566 - accuracy: 0.7278 - val_loss: 0.6626 - val_accuracy: 0.7485\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 3s 118ms/step - loss: 0.4414 - accuracy: 0.8064 - val_loss: 0.6431 - val_accuracy: 0.7544\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 3s 115ms/step - loss: 0.3612 - accuracy: 0.8694 - val_loss: 0.6289 - val_accuracy: 0.7485\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f4b846bc160>"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    x = X_train_emb,\n",
    "    y = y_train_emb,\n",
    "    batch_size=64,\n",
    "    validation_data=(X_test_emb, y_test_emb),\n",
    "    epochs=10,\n",
    "    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/postas/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7771483161165701"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_nn = model.predict_proba(X_test_emb)\n",
    "roc_auc_score(y_test_emb, preds_nn, multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ну... еще процентик отыграть можно )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 10252), started 1:04:41 ago. (Use '!kill 10252' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-bdad135538ee2e64\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-bdad135538ee2e64\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы..\n",
    "Вобщем задача не проста ) Возможно у нас мало данных в датасете, чтобы хорошо натренировать классификацию, возможно стоит думать в сторону разработки дополнительных фичей, более навороченных моделей, поскольку дефолтные методы, что в классических ML подходах, что в нейросетях дают сравнимые результаты. \n",
    "\n",
    "Эмбеддинги Word2Vec что-то совсем не показали..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
