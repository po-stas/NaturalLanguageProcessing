{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ДЗ №9\n",
    "Языковое моделирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Для начала нужен текст.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import html\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from typing import List, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agent = {\n",
    "        'User-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/78.0.3904.108 Safari/537.36'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Стругацкие.. Хромая судьба\n",
    "link = 'https://knijky.ru/books/gadkie-lebedi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_page(response: str) -> str:\n",
    "    result = ''\n",
    "    root = html.fromstring(response)\n",
    "    tables = root.xpath('//div[contains(@class, \"body size\")]/table')\n",
    "    if tables:\n",
    "        table = tables[0]\n",
    "        for paragraph in table.xpath('//p'):\n",
    "            text = paragraph.text\n",
    "            if text:\n",
    "                text = text.replace('&nbsp;', ' ')\n",
    "                text = text.replace('\\xa0', ' ')\n",
    "                result += text.strip()\n",
    "                \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_text = ''\n",
    "response = requests.get(link, headers=user_agent)\n",
    "page = 0\n",
    "while(1):\n",
    "    if not response.ok:\n",
    "        break\n",
    "    whole_text += parse_page(response.text)\n",
    "    page += 1\n",
    "    response = requests.get(f'https://knijky.ru/books/gadkie-lebedi?page={page}', headers=user_agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1Когда Ирма вышла, аккуратно притворив за собой дверь, длинноногая, по-взрослому вежливо улыбаясь большим ртом с яркими, как у матери, губами, Виктор принялся старательно раскуривать сигарету. Это не ребенок, думал он ошеломленно. Дети так не говорят. Это даже не грубость, - это жестокость, и даже не жестокость, а просто ей все равно. Как будто она нам тут теорему доказала, просчитала все, проанализировала, деловито сообщила результат и удалилась, подрагивая косичками, совершенно спокойная. Превозмогая неловкость, Виктор посмотрел на Лолу. Лицо ее шло красными пятнами, яркие губы дрожали, словно она собиралась заплакать, но она, конечно, не думала плакать, она была в бешенстве.-  Ты видишь? - сказала она высоким голосом. - Девчонка, соплячка… Дрянь! Ничего святого, что ни слово-то оскорбление, словно я не мать, а половая тряпка, о которую можно вытирать ноги. Перед соседкой стыдно! Мерзавка, хамка…Да, подумал Виктор, и с этой женщиной я жил. Я гулял с нею в горах, я читал ей Бодлера, и'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69644"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(whole_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Не вся книга конечно... сколько дали на сайте )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text.txt', 'w') as out:\n",
    "    out.write(whole_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text.txt', 'r') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''.join([char for char in text if not char.isdigit()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapping from unique characters to indices\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "idx2char = np.array(vocab)\n",
    "\n",
    "text_as_int = np.array([char2idx[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "К\n",
      "о\n",
      "г\n",
      "д\n",
      "а\n",
      " \n",
      "И\n",
      "р\n",
      "м\n",
      "а\n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence you want for a single input in characters\n",
    "seq_length = 500\n",
    "examples_per_epoch = len(text)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "char_dataset = tf.data.Dataset.from_tensor_slices(text_as_int)\n",
    "\n",
    "for i in char_dataset.take(10):\n",
    "    print(idx2char[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Когда Ирма вышла, аккуратно притворив за собой дверь, длинноногая, по-взрослому вежливо улыбаясь большим ртом с яркими, как у матери, губами, Виктор принялся старательно раскуривать сигарету. Это не ребенок, думал он ошеломленно. Дети так не говорят. Это даже не грубость, - это жестокость, и даже не жестокость, а просто ей все равно. Как будто она нам тут теорему доказала, просчитала все, проанализировала, деловито сообщила результат и удалилась, подрагивая косичками, совершенно спокойная. Превоз'\n",
      "'могая неловкость, Виктор посмотрел на Лолу. Лицо ее шло красными пятнами, яркие губы дрожали, словно она собиралась заплакать, но она, конечно, не думала плакать, она была в бешенстве.-  Ты видишь? - сказала она высоким голосом. - Девчонка, соплячка… Дрянь! Ничего святого, что ни слово-то оскорбление, словно я не мать, а половая тряпка, о которую можно вытирать ноги. Перед соседкой стыдно! Мерзавка, хамка…Да, подумал Виктор, и с этой женщиной я жил. Я гулял с нею в горах, я читал ей Бодлера, и тр'\n",
      "'епетал, когда прикасался к ней, и помнил ее запах… Кажется даже дрался из-за нее. До сих пор не понимаю, что она думала, когда я читал ей Бодлера? Нет, это просто удивительно, что мне удалось от нее удрать. Уму непостижимо, и как она меня выпустила? Наверно, я тоже был не сахар. Наверное, я и сейчас не сахар, но тогда я пил еще больше чем сейчас, и к тому же полагал себя большим поэтом.-  Тебе, конечно, не до того, куда там, - говорила Лола. - Столичная жизнь, всякие балерины, артистки… Я все зна'\n",
      "'ю. Не воображай, что мы здесь ничего не знаем. И деньги конечно, бешеные, и любовницы, и бесконечные скандалы… Мне это, если хочешь ты знать, безразлично, я тебе не мешала, ты жил как хотел…Вообще ее губит то, что она очень много говорит, в девицах она была тихая, молчаливая, таинственная. Есть такие девицы, которые от рождения знают, как себя надо вести. Она знала. Вообще то она и сейчас ничего, когда сидит, например, молча, на диване с сигаретой, выставив колени… Или заломит вдруг руку за голов'\n",
      "'у и потянется. На провинциального адвоката это должно действовать чрезвычайно… Виктор представил себе уютный вечерок, этот столик придвинут к тому вон дивану, бутылка, шампанское шипит в фужерах, перевязанная ленточкой коробка шоколаду и сам адвокат, закованный в крахмал, галстук бабочкой. Все как у людей, и вдруг входит Ирма… Кошмар, подумал Виктор. Да она же несчастная женщина…-  Ты сам должен понимать, - говорила Лола, - что дело не в деньгах, что не деньги сейчас все решают. - Она уже успокои'\n"
     ]
    }
   ],
   "source": [
    "sequences = char_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2char[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 500), (64, 500)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 500, 74) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'еку.Виктор ощутил какой-то холод внутри. Какое-то беспокойство. Или даже страх. Словно в лицо ему расхохоталась кошка.-  Естественное всегда примитивно, - продолжал между прочим Бол-Кунац.-  А человек - существо сложное, естественность ему не идет. Вы понимаете меня, господин Банев?-  Да, - сказал Виктор, - конечно…Было нечто удивительно фальшивое в том, что он отечески держал руку на плече этого мальчишки, который не мальчишка. У него даже заныло в локте. Он осторожно убрал руку и сунул ее в ка'\n",
      "\n",
      "Next Char Predictions: \n",
      " 'шгю?цЛмжПцяф,ХО&ББ!фЮгНбХЛРЖ))рbЗ(йНрвЛnnдДБЮЛ)ыУ…оЕуАШн…УnУэюяС)ейъЭГО?гЕ-оЮпнфВю?КТзРпрШb-ГРоиг»Зуч-ТВоЭзлЯвЮк&уОПУчфЕККжщЭвыЭО-?цнХьКФРаЭвэв;ЯжбхЛЗЛнЯnЖНЕщп. УЖи,ЗКЧжаКх(!!тЖлЯБТКщмзлnЭ&щпшчз&Ф,яТЮ…КхойВЗнп»ЭЮ«ЮеШ…ЭУ(хвЭ:х!…ПМкФ.ЯфысБиА.а!Н»ЯхХЛтъЛкbлЯУвГ.»Вч…тДиПnфириюЕнБиЭцяЮк«-жКшжнНn;гЧ-В&ыМЧ-Ф;КЖТБВОе(ЛbэУю;ЛэЮнозллВУ&тцф!МПм»фБТцр.уЮБНржшшзШхЖ(Уб»РФчБ,оbМ,Фввщц фщБНыПЖ,йрГТ)НгГВХъьЮУьАи-РчРДЖ&П!кжуКЧ;чдщ  Еь(МдрЖ)сЭ.ъьИбЮП;БщНж.бккю лч.ШеЭрВлыМтВЯЧИлКдшnФХЗФсцЮе?яЮГчеюпхУиэнвыИчЯэЖрКыНШ'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(\"\".join(idx2char[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Char Predictions: \\n\", repr(\"\".join(idx2char[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 500, 74)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       4.303657\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    period=20,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 3.2562\n",
      "Epoch 2/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 3.2501\n",
      "Epoch 3/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 3.2468\n",
      "Epoch 4/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 3.2412\n",
      "Epoch 5/400\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 3.2348\n",
      "Epoch 6/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 3.2256\n",
      "Epoch 7/400\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 3.2128\n",
      "Epoch 8/400\n",
      "2/2 [==============================] - 1s 432ms/step - loss: 3.2035\n",
      "Epoch 9/400\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 3.1887\n",
      "Epoch 10/400\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 3.1675\n",
      "Epoch 11/400\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 3.1539\n",
      "Epoch 12/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 3.1420\n",
      "Epoch 13/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 3.1440\n",
      "Epoch 14/400\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 3.1183\n",
      "Epoch 15/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 3.0996\n",
      "Epoch 16/400\n",
      "2/2 [==============================] - 1s 273ms/step - loss: 3.0796\n",
      "Epoch 17/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 3.0623\n",
      "Epoch 18/400\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 3.0493\n",
      "Epoch 19/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 3.0236\n",
      "Epoch 20/400\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 3.0123\n",
      "Epoch 21/400\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 2.9959\n",
      "Epoch 22/400\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 2.9802\n",
      "Epoch 23/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 2.9639\n",
      "Epoch 24/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 2.9475\n",
      "Epoch 25/400\n",
      "2/2 [==============================] - 1s 391ms/step - loss: 2.9313\n",
      "Epoch 26/400\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 2.9137\n",
      "Epoch 27/400\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 2.8956\n",
      "Epoch 28/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 2.8776\n",
      "Epoch 29/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 2.8633\n",
      "Epoch 30/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 2.8432\n",
      "Epoch 31/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 2.8231\n",
      "Epoch 32/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 2.8086\n",
      "Epoch 33/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 2.7915\n",
      "Epoch 34/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 2.7713\n",
      "Epoch 35/400\n",
      "2/2 [==============================] - 1s 316ms/step - loss: 2.7501\n",
      "Epoch 36/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 2.7300\n",
      "Epoch 37/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 2.7267\n",
      "Epoch 38/400\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 2.7121\n",
      "Epoch 39/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 2.6881\n",
      "Epoch 40/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 2.6684\n",
      "Epoch 41/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 2.6510\n",
      "Epoch 42/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 2.6275\n",
      "Epoch 43/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 2.6140\n",
      "Epoch 44/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 2.6139\n",
      "Epoch 45/400\n",
      "2/2 [==============================] - 1s 276ms/step - loss: 2.5975\n",
      "Epoch 46/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 2.5777\n",
      "Epoch 47/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 2.5637\n",
      "Epoch 48/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 2.5551\n",
      "Epoch 49/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 2.5473\n",
      "Epoch 50/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 2.5244\n",
      "Epoch 51/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 2.5120\n",
      "Epoch 52/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 2.5017\n",
      "Epoch 53/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 2.4852\n",
      "Epoch 54/400\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 2.4706\n",
      "Epoch 55/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 2.4546\n",
      "Epoch 56/400\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 2.4431\n",
      "Epoch 57/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 2.4308\n",
      "Epoch 58/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 2.4116\n",
      "Epoch 59/400\n",
      "2/2 [==============================] - 1s 387ms/step - loss: 2.3972\n",
      "Epoch 60/400\n",
      "2/2 [==============================] - 1s 383ms/step - loss: 2.3853\n",
      "Epoch 61/400\n",
      "2/2 [==============================] - 1s 425ms/step - loss: 2.3825\n",
      "Epoch 62/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 2.3651\n",
      "Epoch 63/400\n",
      "2/2 [==============================] - 1s 358ms/step - loss: 2.3460\n",
      "Epoch 64/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 2.3325\n",
      "Epoch 65/400\n",
      "2/2 [==============================] - 1s 320ms/step - loss: 2.3249\n",
      "Epoch 66/400\n",
      "2/2 [==============================] - 1s 333ms/step - loss: 2.3118\n",
      "Epoch 67/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 2.3020\n",
      "Epoch 68/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 2.2789\n",
      "Epoch 69/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 2.2768\n",
      "Epoch 70/400\n",
      "2/2 [==============================] - 1s 313ms/step - loss: 2.2599\n",
      "Epoch 71/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 2.2512\n",
      "Epoch 72/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 2.2434\n",
      "Epoch 73/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 2.2302\n",
      "Epoch 74/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 2.2111\n",
      "Epoch 75/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 2.2002\n",
      "Epoch 76/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 2.1875\n",
      "Epoch 77/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 2.1724\n",
      "Epoch 78/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 2.1522\n",
      "Epoch 79/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 2.1490\n",
      "Epoch 80/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 2.1398\n",
      "Epoch 81/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 2.1236\n",
      "Epoch 82/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 2.1039\n",
      "Epoch 83/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 2.0976\n",
      "Epoch 84/400\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 2.0885\n",
      "Epoch 85/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 2.0714\n",
      "Epoch 86/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 2.0551\n",
      "Epoch 87/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 2.0456\n",
      "Epoch 88/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 2.0413\n",
      "Epoch 89/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 2.0191\n",
      "Epoch 90/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 1.9914\n",
      "Epoch 91/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 1.9756\n",
      "Epoch 92/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 1.9609\n",
      "Epoch 93/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 1.9537\n",
      "Epoch 94/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 1.9355\n",
      "Epoch 95/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 1.9286\n",
      "Epoch 96/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 1.9250\n",
      "Epoch 97/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 1.9021\n",
      "Epoch 98/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 1.8844\n",
      "Epoch 99/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 1.8654\n",
      "Epoch 100/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 1.8379\n",
      "Epoch 101/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 1.8229\n",
      "Epoch 102/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 1.8106\n",
      "Epoch 103/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 1.8039\n",
      "Epoch 104/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 1.7687\n",
      "Epoch 105/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 1.7492\n",
      "Epoch 106/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 1.7209\n",
      "Epoch 107/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 1.7115\n",
      "Epoch 108/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 1.6937\n",
      "Epoch 109/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 1.6725\n",
      "Epoch 110/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 1.6580\n",
      "Epoch 111/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 1.6174\n",
      "Epoch 112/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 1.6037\n",
      "Epoch 113/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 1.5976\n",
      "Epoch 114/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 1.5918\n",
      "Epoch 115/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 1.5730\n",
      "Epoch 116/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 1.5314\n",
      "Epoch 117/400\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 1.4926\n",
      "Epoch 118/400\n",
      "2/2 [==============================] - 1s 327ms/step - loss: 1.4440\n",
      "Epoch 119/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 1.4089\n",
      "Epoch 120/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 1.4013\n",
      "Epoch 121/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 1.3754\n",
      "Epoch 122/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 1.3558\n",
      "Epoch 123/400\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 1.3301\n",
      "Epoch 124/400\n",
      "2/2 [==============================] - 1s 342ms/step - loss: 1.3084\n",
      "Epoch 125/400\n",
      "2/2 [==============================] - 1s 323ms/step - loss: 1.2773\n",
      "Epoch 126/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 1.2349\n",
      "Epoch 127/400\n",
      "2/2 [==============================] - 1s 307ms/step - loss: 1.1790\n",
      "Epoch 128/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 1.1370\n",
      "Epoch 129/400\n",
      "2/2 [==============================] - 1s 328ms/step - loss: 1.1239\n",
      "Epoch 130/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 1.1240\n",
      "Epoch 131/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 1.1010\n",
      "Epoch 132/400\n",
      "2/2 [==============================] - 1s 405ms/step - loss: 1.0872\n",
      "Epoch 133/400\n",
      "2/2 [==============================] - 1s 320ms/step - loss: 1.0264\n",
      "Epoch 134/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.9962\n",
      "Epoch 135/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.9410\n",
      "Epoch 136/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.8939\n",
      "Epoch 137/400\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.8475\n",
      "Epoch 138/400\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.7995\n",
      "Epoch 139/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.7591\n",
      "Epoch 140/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.7371\n",
      "Epoch 141/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.7004\n",
      "Epoch 142/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.6787\n",
      "Epoch 143/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.6402\n",
      "Epoch 144/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.6458\n",
      "Epoch 145/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.6552\n",
      "Epoch 146/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.6656\n",
      "Epoch 147/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.6232\n",
      "Epoch 148/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.5812\n",
      "Epoch 149/400\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.5321\n",
      "Epoch 150/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.4950\n",
      "Epoch 151/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.4606\n",
      "Epoch 152/400\n",
      "2/2 [==============================] - 1s 307ms/step - loss: 0.4275\n",
      "Epoch 153/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.3970\n",
      "Epoch 154/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.3709\n",
      "Epoch 155/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.3487\n",
      "Epoch 156/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.3204\n",
      "Epoch 157/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.3040\n",
      "Epoch 158/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.2793\n",
      "Epoch 159/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.2657\n",
      "Epoch 160/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.2513\n",
      "Epoch 161/400\n",
      "2/2 [==============================] - 1s 319ms/step - loss: 0.2327\n",
      "Epoch 162/400\n",
      "2/2 [==============================] - 1s 307ms/step - loss: 0.2274\n",
      "Epoch 163/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.2109\n",
      "Epoch 164/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.2052\n",
      "Epoch 165/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.1930\n",
      "Epoch 166/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.1830\n",
      "Epoch 167/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.1780\n",
      "Epoch 168/400\n",
      "2/2 [==============================] - 1s 322ms/step - loss: 0.1715\n",
      "Epoch 169/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.1678\n",
      "Epoch 170/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.1601\n",
      "Epoch 171/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.1572\n",
      "Epoch 172/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.1501\n",
      "Epoch 173/400\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.1457\n",
      "Epoch 174/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.1396\n",
      "Epoch 175/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.1364\n",
      "Epoch 176/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.1307\n",
      "Epoch 177/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.1301\n",
      "Epoch 178/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.1281\n",
      "Epoch 179/400\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.1258\n",
      "Epoch 180/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.1231\n",
      "Epoch 181/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.1194\n",
      "Epoch 182/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.1179\n",
      "Epoch 183/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.1124\n",
      "Epoch 184/400\n",
      "2/2 [==============================] - 1s 332ms/step - loss: 0.1125\n",
      "Epoch 185/400\n",
      "2/2 [==============================] - 1s 307ms/step - loss: 0.1091\n",
      "Epoch 186/400\n",
      "2/2 [==============================] - 1s 378ms/step - loss: 0.1109\n",
      "Epoch 187/400\n",
      "2/2 [==============================] - 1s 307ms/step - loss: 0.1070\n",
      "Epoch 188/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.1018\n",
      "Epoch 189/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.1050\n",
      "Epoch 190/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0991\n",
      "Epoch 191/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0997\n",
      "Epoch 192/400\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.0983\n",
      "Epoch 193/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0941\n",
      "Epoch 194/400\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.0949\n",
      "Epoch 195/400\n",
      "2/2 [==============================] - 1s 308ms/step - loss: 0.0913\n",
      "Epoch 196/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0909\n",
      "Epoch 197/400\n",
      "2/2 [==============================] - 1s 308ms/step - loss: 0.0893\n",
      "Epoch 198/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0877\n",
      "Epoch 199/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0870\n",
      "Epoch 200/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0865\n",
      "Epoch 201/400\n",
      "2/2 [==============================] - 1s 280ms/step - loss: 0.0830\n",
      "Epoch 202/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0864\n",
      "Epoch 203/400\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 0.0817\n",
      "Epoch 204/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0822\n",
      "Epoch 205/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0804\n",
      "Epoch 206/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0793\n",
      "Epoch 207/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0780\n",
      "Epoch 208/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0774\n",
      "Epoch 209/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0757\n",
      "Epoch 210/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0753\n",
      "Epoch 211/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0730\n",
      "Epoch 212/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0720\n",
      "Epoch 213/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0717\n",
      "Epoch 214/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0730\n",
      "Epoch 215/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0719\n",
      "Epoch 216/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0692\n",
      "Epoch 217/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0699\n",
      "Epoch 218/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0699\n",
      "Epoch 219/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0693\n",
      "Epoch 220/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0671\n",
      "Epoch 221/400\n",
      "2/2 [==============================] - 1s 308ms/step - loss: 0.0649\n",
      "Epoch 222/400\n",
      "2/2 [==============================] - 1s 308ms/step - loss: 0.0643\n",
      "Epoch 223/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0658\n",
      "Epoch 224/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0649\n",
      "Epoch 225/400\n",
      "2/2 [==============================] - 1s 307ms/step - loss: 0.0628\n",
      "Epoch 226/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0619\n",
      "Epoch 227/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0609\n",
      "Epoch 228/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0620\n",
      "Epoch 229/400\n",
      "2/2 [==============================] - 1s 307ms/step - loss: 0.0592\n",
      "Epoch 230/400\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.0601\n",
      "Epoch 231/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0602\n",
      "Epoch 232/400\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.0587\n",
      "Epoch 233/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0577\n",
      "Epoch 234/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0599\n",
      "Epoch 235/400\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.0563\n",
      "Epoch 236/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0576\n",
      "Epoch 237/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0567\n",
      "Epoch 238/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0556\n",
      "Epoch 239/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0553\n",
      "Epoch 240/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0561\n",
      "Epoch 241/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0557\n",
      "Epoch 242/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0528\n",
      "Epoch 243/400\n",
      "2/2 [==============================] - 1s 317ms/step - loss: 0.0531\n",
      "Epoch 244/400\n",
      "2/2 [==============================] - 1s 307ms/step - loss: 0.0529\n",
      "Epoch 245/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0533\n",
      "Epoch 246/400\n",
      "2/2 [==============================] - 1s 337ms/step - loss: 0.0522\n",
      "Epoch 247/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0505\n",
      "Epoch 248/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0513\n",
      "Epoch 249/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0487\n",
      "Epoch 250/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0495\n",
      "Epoch 251/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0523\n",
      "Epoch 252/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0502\n",
      "Epoch 253/400\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.0495\n",
      "Epoch 254/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0479\n",
      "Epoch 255/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0471\n",
      "Epoch 256/400\n",
      "2/2 [==============================] - 1s 308ms/step - loss: 0.0477\n",
      "Epoch 257/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0462\n",
      "Epoch 258/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0494\n",
      "Epoch 259/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0461\n",
      "Epoch 260/400\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.0467\n",
      "Epoch 261/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0486\n",
      "Epoch 262/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0479\n",
      "Epoch 263/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0447\n",
      "Epoch 264/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0457\n",
      "Epoch 265/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0441\n",
      "Epoch 266/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0466\n",
      "Epoch 267/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0441\n",
      "Epoch 268/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0446\n",
      "Epoch 269/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0425\n",
      "Epoch 270/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0457\n",
      "Epoch 271/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0438\n",
      "Epoch 272/400\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.0435\n",
      "Epoch 273/400\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.0429\n",
      "Epoch 274/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0430\n",
      "Epoch 275/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0409\n",
      "Epoch 276/400\n",
      "2/2 [==============================] - 1s 318ms/step - loss: 0.0407\n",
      "Epoch 277/400\n",
      "2/2 [==============================] - 1s 308ms/step - loss: 0.0417\n",
      "Epoch 278/400\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.0410\n",
      "Epoch 279/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0412\n",
      "Epoch 280/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0394\n",
      "Epoch 281/400\n",
      "2/2 [==============================] - 1s 309ms/step - loss: 0.0405\n",
      "Epoch 282/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0402\n",
      "Epoch 283/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0397\n",
      "Epoch 284/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0409\n",
      "Epoch 285/400\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.0378\n",
      "Epoch 286/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0380\n",
      "Epoch 287/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0393\n",
      "Epoch 288/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0367\n",
      "Epoch 289/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0399\n",
      "Epoch 290/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0393\n",
      "Epoch 291/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0388\n",
      "Epoch 292/400\n",
      "2/2 [==============================] - 1s 321ms/step - loss: 0.0405\n",
      "Epoch 293/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0385\n",
      "Epoch 294/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0370\n",
      "Epoch 295/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0377\n",
      "Epoch 296/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0378\n",
      "Epoch 297/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0372\n",
      "Epoch 298/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0359\n",
      "Epoch 299/400\n",
      "2/2 [==============================] - 1s 279ms/step - loss: 0.0355\n",
      "Epoch 300/400\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.0390\n",
      "Epoch 301/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0373\n",
      "Epoch 302/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0360\n",
      "Epoch 303/400\n",
      "2/2 [==============================] - 1s 282ms/step - loss: 0.0361\n",
      "Epoch 304/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0368\n",
      "Epoch 305/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0359\n",
      "Epoch 306/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0346\n",
      "Epoch 307/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0353\n",
      "Epoch 308/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0344\n",
      "Epoch 309/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0337\n",
      "Epoch 310/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0350\n",
      "Epoch 311/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0364\n",
      "Epoch 312/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0335\n",
      "Epoch 313/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0336\n",
      "Epoch 314/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0331\n",
      "Epoch 315/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0337\n",
      "Epoch 316/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0324\n",
      "Epoch 317/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0331\n",
      "Epoch 318/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0324\n",
      "Epoch 319/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0341\n",
      "Epoch 320/400\n",
      "2/2 [==============================] - 1s 330ms/step - loss: 0.0323\n",
      "Epoch 321/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0310\n",
      "Epoch 322/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0341\n",
      "Epoch 323/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0312\n",
      "Epoch 324/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0314\n",
      "Epoch 325/400\n",
      "2/2 [==============================] - 1s 307ms/step - loss: 0.0312\n",
      "Epoch 326/400\n",
      "2/2 [==============================] - 1s 313ms/step - loss: 0.0315\n",
      "Epoch 327/400\n",
      "2/2 [==============================] - 1s 307ms/step - loss: 0.0311\n",
      "Epoch 328/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0316\n",
      "Epoch 329/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0301\n",
      "Epoch 330/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0318\n",
      "Epoch 331/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0306\n",
      "Epoch 332/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0295\n",
      "Epoch 333/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0295\n",
      "Epoch 334/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0300\n",
      "Epoch 335/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0293\n",
      "Epoch 336/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0293\n",
      "Epoch 337/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0283\n",
      "Epoch 338/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0294\n",
      "Epoch 339/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0297\n",
      "Epoch 340/400\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.0285\n",
      "Epoch 341/400\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.0289\n",
      "Epoch 342/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0287\n",
      "Epoch 343/400\n",
      "2/2 [==============================] - 1s 308ms/step - loss: 0.0286\n",
      "Epoch 344/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0286\n",
      "Epoch 345/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0280\n",
      "Epoch 346/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0273\n",
      "Epoch 347/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0273\n",
      "Epoch 348/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0286\n",
      "Epoch 349/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0275\n",
      "Epoch 350/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0277\n",
      "Epoch 351/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0286\n",
      "Epoch 352/400\n",
      "2/2 [==============================] - 1s 307ms/step - loss: 0.0265\n",
      "Epoch 353/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0277\n",
      "Epoch 354/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0273\n",
      "Epoch 355/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0283\n",
      "Epoch 356/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0267\n",
      "Epoch 357/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0286\n",
      "Epoch 358/400\n",
      "2/2 [==============================] - 1s 309ms/step - loss: 0.0277\n",
      "Epoch 359/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0261\n",
      "Epoch 360/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0261\n",
      "Epoch 361/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0276\n",
      "Epoch 362/400\n",
      "2/2 [==============================] - 1s 308ms/step - loss: 0.0268\n",
      "Epoch 363/400\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.0268\n",
      "Epoch 364/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0262\n",
      "Epoch 365/400\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.0254\n",
      "Epoch 366/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0256\n",
      "Epoch 367/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0261\n",
      "Epoch 368/400\n",
      "2/2 [==============================] - 1s 307ms/step - loss: 0.0254\n",
      "Epoch 369/400\n",
      "2/2 [==============================] - 1s 281ms/step - loss: 0.0260\n",
      "Epoch 370/400\n",
      "2/2 [==============================] - 1s 309ms/step - loss: 0.0261\n",
      "Epoch 371/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0248\n",
      "Epoch 372/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0237\n",
      "Epoch 373/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0264\n",
      "Epoch 374/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0257\n",
      "Epoch 375/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0248\n",
      "Epoch 376/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0244\n",
      "Epoch 377/400\n",
      "2/2 [==============================] - 1s 308ms/step - loss: 0.0250\n",
      "Epoch 378/400\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.0241\n",
      "Epoch 379/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0243\n",
      "Epoch 380/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0244\n",
      "Epoch 381/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0240\n",
      "Epoch 382/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0252\n",
      "Epoch 383/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0250\n",
      "Epoch 384/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0233\n",
      "Epoch 385/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0238\n",
      "Epoch 386/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0246\n",
      "Epoch 387/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0239\n",
      "Epoch 388/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0238\n",
      "Epoch 389/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0231\n",
      "Epoch 390/400\n",
      "2/2 [==============================] - 1s 312ms/step - loss: 0.0243\n",
      "Epoch 391/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0242\n",
      "Epoch 392/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0239\n",
      "Epoch 393/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0234\n",
      "Epoch 394/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0222\n",
      "Epoch 395/400\n",
      "2/2 [==============================] - 1s 306ms/step - loss: 0.0236\n",
      "Epoch 396/400\n",
      "2/2 [==============================] - 1s 307ms/step - loss: 0.0243\n",
      "Epoch 397/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0234\n",
      "Epoch 398/400\n",
      "2/2 [==============================] - 1s 307ms/step - loss: 0.0230\n",
      "Epoch 399/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0230\n",
      "Epoch 400/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0220\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, temperature=0.0001, num_generate=500):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    # Number of characters to generate\n",
    "    # num_generate = 500\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [char2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperature results in more predictable text.\n",
    "    # Higher temperature results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        # using a categorical distribution to predict the character returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        # Pass the predicted character as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2char[predicted_id])\n",
    "\n",
    "    return (start_string + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 256)            18944     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (1, None, 1024)           5246976   \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (1, None, 1024)           8392704   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 74)             75850     \n",
      "=================================================================\n",
      "Total params: 13,734,474\n",
      "Trainable params: 13,734,474\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Как сказать и тапетство в подекной сказалену дрифанстим в чероси и боз этого нел вызли, на выга с мокранум. - Повордила то баз рекиненот. И я ни програзилась казался синевати-белым. Виктор сел рядом на ступеньку. Ему хотелось уйти в вестибюль, но это было невозможно - оставить под проливным дождем раненого человека, а самому уйти в тепло. «Сколько раз меня сегодня называли дураком?» - подумал он, обтирая лицо ладонью. Ох, что-то много. И, кажется, в этом есть доля истины, поскольку, дурак, он же болван, он '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, start_string=u\"Как сказать \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Какая жесть!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Как сказать и тапетство в подекной сказал ез не сволой.   Я спелано  погоднов стаялусь и соворвались по катоной нилобых стату в мостаной сватиную, в дреманный в под берек бавестещену и нал поверод шлей востанили прядел и отпоминем, опросторнул вернома ограстала скомости мерной, а все бедь придержилась за кдисть, стал не разибать, то Виктор уже спал и схах и потянется и за прежнилась под сторен нам нестодем гумнасии камня… Ты все прикажись себя, а потло незал будыть поразалать. Вактор придло говори. - Опядит'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, start_string=u\"Как сказать \", temperature=0.11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Как сказать и датал, кат они и Голем поднол глаза и смотрел на него, и Тэдди за своей стойкой тоже перестал перетирать бутылки и прислушался, только вот затылок вдруг заломило, и пришлось поставить рюмку и погладить желвак.-  Государственный аппарат, господа, во все времена почитал своей главной задачей сохранение статус-кво. Не знаю, насколько это было оправдано раньше, но сейчас такая функция государства просто необходима. Я бы определил ее так: всячески препятствовать будущему, запускать свои щупальца в '"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, start_string=u\"Как сказать \", temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'мокрецы - И потом, какие пророки в наше время? Я не знаю ни одного. Множество лжепророков и ни одного пророка. В наше время нельзя предвидеть будущее - это насилие над языком. Чтобы вы сказали, прочитав у Шекспира: предвидеть настоящее? Разве можно предвидеть шкаф в собственной комнате?.. А вот идет мой инспектор. Как вы себя чувствуете, инспектор?-  Прекрасно, - сказал Павор, усаживаясь. - Официант, двойной коньяк! Там, в вестибюле, нашего живописца держат четверо, - сообщил он. - Объясняют ему, где вх'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, start_string=u\"мокрецы \", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'мокрецы - И потом, какие пророки в наше время? Я не знаю ни одного. Множество лжепророков и ни одного пророка. В наше время нельзя предвидеть будущее - это насилие над языком. Чтобы вы сказали, прочитав у Шекспира: предвидеть настоящее? Разве можно предвидеть шкаф в собственной комнате?.. А вот идет мой инспектор. Как вы себя чувствуете, инспектор?-  Прекрасно, - сказал Павор, усаживаясь. - Официант, двойной коньяк! Там, в вестибюле, нашего живописца держат четверо, - сообщил он. - Объясняют ему, где вх'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, start_string=u\"мокрецы \", temperature=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'мокрецы - И потом, какие пророки в наше время? Я не знаю ни одного. Множество лжепророков и ни одного пророка. В наше время нельзя предвидеть будущее - это насилие над языком. Чтобы вы сказали, прочитав у Шекспира: предвидеть настоящее? Разве можно предвидеть шкаф в собственной комнате?.. А вот идет мой инспектор. Как вы себя чувствуете, инспектор?-  Прекрасно, - сказал Павор, усаживаясь. - Официант, двойной коньяк! Там, в вестибюле, нашего живописца держат четверо, - сообщил он. - Объясняют ему, где вх'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, start_string=u\"мокрецы \", temperature=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вобщем при каком то значении температуры начинает цитировать первоисточник. \n",
    "# А иначе - даже слова не может построить правильно )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Виктор остарожилась оз кростыл каждую залошта, ни остановился и ущется ладина у ничаго не бодля. Послодой маспокиже кропом в растеначенный свалодарюм на всерка и все естадетно в ходама на истех. В Я ваз блестий поволил ее мучели н под окнами темнели лужи.-  А что он здесь делал ночью? - спросил Виктор.-  Где? - спросила Диана, не оборачиваясь.-  На тропинке… Ты ведь знала, что он здесь?-  Ну, понимаешь, - сказала она, - в лепрозории плохо с медикаментами. Иногда они приходят к нам, просят…Она закрыла последнее окно и прошлась по лаборатории, оглядывая столы, заставленные приборами и химической посудой.-  Гнусно все это, - сказал Виктор. - Ну и государство. Куда ни приедешь - везде какая-нибудь дрянь… Пошли, а то я замерз.&накари по русуму. В своди к глино придеринист бы стелся, но мелонись по бутном полому назого. У конет терого они всел в росторой на семанари разал Виктор. - Шаг влево, шаг вправо, - стреляю.Диана пролезла первой и посветила Виктору. Потом они очень медленно двинулись под гор'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, start_string=u\"Виктор \", temperature=0.2, num_generate=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Шедевры!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc26d7c38b0>]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Хотя можно наверное и еще поучить было.. учится быстро"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints2'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    period=20,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.iter\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.decay\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'm' for (root).layer_with_weights-2.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-0.embeddings\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-3.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-1.cell.bias\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.recurrent_kernel\n",
      "WARNING:tensorflow:Unresolved object in checkpoint: (root).optimizer's state 'v' for (root).layer_with_weights-2.cell.bias\n",
      "WARNING:tensorflow:A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/guide/checkpoint#loading_mechanics for details.\n",
      "2/2 [==============================] - 7s 903ms/step - loss: 4.2510\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 2s 909ms/step - loss: 5.4872\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 2s 916ms/step - loss: 4.1406\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 2s 909ms/step - loss: 3.6156\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 2s 907ms/step - loss: 3.3365\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.3117\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 2s 903ms/step - loss: 3.2997\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 2s 900ms/step - loss: 3.2956\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 2s 906ms/step - loss: 3.2742\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 2s 916ms/step - loss: 3.2761\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 2s 912ms/step - loss: 3.2722\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 2s 921ms/step - loss: 3.2718\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 2s 914ms/step - loss: 3.2610\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 2s 911ms/step - loss: 3.2626\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 2s 939ms/step - loss: 3.2645\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 2s 971ms/step - loss: 3.2595\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 2s 934ms/step - loss: 3.2543\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 2s 943ms/step - loss: 3.2575\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 2s 967ms/step - loss: 3.2559\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 2s 929ms/step - loss: 3.2547\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 2s 924ms/step - loss: 3.2565\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 2s 920ms/step - loss: 3.2527\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 2s 924ms/step - loss: 3.2552\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 2s 923ms/step - loss: 3.2532\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 2s 926ms/step - loss: 3.2567\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 2s 965ms/step - loss: 3.2526\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 2s 923ms/step - loss: 3.2548\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 2s 917ms/step - loss: 3.2569\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 2s 925ms/step - loss: 3.2528\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 2s 927ms/step - loss: 3.2520\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 2s 922ms/step - loss: 3.2497\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 2s 932ms/step - loss: 3.2545\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.2524\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.2575\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 2s 953ms/step - loss: 3.2516\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.2548\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.2548\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 2s 938ms/step - loss: 3.2540\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.2521\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 2s 948ms/step - loss: 3.2510\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 2s 929ms/step - loss: 3.2548\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 2s 938ms/step - loss: 3.2542\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 2s 928ms/step - loss: 3.2503\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 2s 933ms/step - loss: 3.2514\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 2s 923ms/step - loss: 3.2507\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 2s 937ms/step - loss: 3.2527\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 2s 930ms/step - loss: 3.2549\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 2s 927ms/step - loss: 3.2488\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 2s 923ms/step - loss: 3.2519\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 2s 934ms/step - loss: 3.2554\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 2s 926ms/step - loss: 3.2548\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 2s 932ms/step - loss: 3.2530\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 2s 928ms/step - loss: 3.2533\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 2s 994ms/step - loss: 3.2541\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 2s 923ms/step - loss: 3.2519\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 2s 947ms/step - loss: 3.2509\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 2s 933ms/step - loss: 3.2544\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 2s 951ms/step - loss: 3.2503\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 2s 925ms/step - loss: 3.2500\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 2s 923ms/step - loss: 3.2535\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.2536\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.2516\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 2s 916ms/step - loss: 3.2508\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 2s 929ms/step - loss: 3.2570\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 2s 928ms/step - loss: 3.2544\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 2s 919ms/step - loss: 3.2505\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 2s 931ms/step - loss: 3.2486\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 2s 930ms/step - loss: 3.2568\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 2s 929ms/step - loss: 3.2549\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 2s 925ms/step - loss: 3.2536\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.2514\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.2533\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 2s 986ms/step - loss: 3.2518\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 2s 925ms/step - loss: 3.2551\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 2s 928ms/step - loss: 3.2516\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.2543\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 2s 922ms/step - loss: 3.2546\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 2s 988ms/step - loss: 3.2512\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 2s 931ms/step - loss: 3.2524\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 2s 934ms/step - loss: 3.2500\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 2s 925ms/step - loss: 3.2506\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 2s 943ms/step - loss: 3.2540\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 2s 933ms/step - loss: 3.2546\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 2s 921ms/step - loss: 3.2540\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 2s 955ms/step - loss: 3.2540\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 2s 930ms/step - loss: 3.2537\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 2s 926ms/step - loss: 3.2548\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 2s 931ms/step - loss: 3.2529\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 2s 933ms/step - loss: 3.2502\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 2s 934ms/step - loss: 3.2552\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 2s 930ms/step - loss: 3.2534\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 2s 907ms/step - loss: 3.2552\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 2s 917ms/step - loss: 3.2543\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 2s 922ms/step - loss: 3.2567\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 2s 931ms/step - loss: 3.2563\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 2s 931ms/step - loss: 3.2515\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 2s 928ms/step - loss: 3.2505\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 2s 925ms/step - loss: 3.2484\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 2s 927ms/step - loss: 3.2516\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 2s 900ms/step - loss: 3.2559\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 2s 925ms/step - loss: 3.2547\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 2s 929ms/step - loss: 3.2565\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 2s 924ms/step - loss: 3.2536\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 2s 961ms/step - loss: 3.2485\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 2s 984ms/step - loss: 3.2552\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 2s 928ms/step - loss: 3.2532\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 2s 924ms/step - loss: 3.2518\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 2s 928ms/step - loss: 3.2497\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 2s 930ms/step - loss: 3.2495\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 2s 934ms/step - loss: 3.2551\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 2s 921ms/step - loss: 3.2491\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 2s 929ms/step - loss: 3.2488\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 2s 930ms/step - loss: 3.2549\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 2s 923ms/step - loss: 3.2534\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 2s 949ms/step - loss: 3.2519\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 2s 926ms/step - loss: 3.2554\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 2s 931ms/step - loss: 3.2528\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 2s 925ms/step - loss: 3.2530\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 2s 934ms/step - loss: 3.2521\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 2s 929ms/step - loss: 3.2553\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 2s 936ms/step - loss: 3.2540\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 2s 933ms/step - loss: 3.2520\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 2s 928ms/step - loss: 3.2523\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 2s 930ms/step - loss: 3.2523\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 2s 927ms/step - loss: 3.2485\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 2s 928ms/step - loss: 3.2533\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 2s 924ms/step - loss: 3.2532\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 2s 929ms/step - loss: 3.2554\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 2s 920ms/step - loss: 3.2500\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 2s 932ms/step - loss: 3.2539\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 2s 935ms/step - loss: 3.2507\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 2s 921ms/step - loss: 3.2545\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 2s 926ms/step - loss: 3.2528\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 2s 923ms/step - loss: 3.2496\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 2s 920ms/step - loss: 3.2504\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 2s 928ms/step - loss: 3.2551\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 2s 935ms/step - loss: 3.2535\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 2s 924ms/step - loss: 3.2542\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 2s 931ms/step - loss: 3.2572\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 2s 934ms/step - loss: 3.2499\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 2s 931ms/step - loss: 3.2536\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 2s 938ms/step - loss: 3.2520\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 2s 926ms/step - loss: 3.2540\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 2s 932ms/step - loss: 3.2527\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 2s 942ms/step - loss: 3.2569\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 2s 927ms/step - loss: 3.2524\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 2s 919ms/step - loss: 3.2534\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 2s 923ms/step - loss: 3.2536\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 2s 923ms/step - loss: 3.2559\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 2s 928ms/step - loss: 3.2532\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 2s 934ms/step - loss: 3.2546\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 2s 931ms/step - loss: 3.2535\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 2s 926ms/step - loss: 3.2519\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 2s 926ms/step - loss: 3.2525\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 2s 921ms/step - loss: 3.2559\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 2s 944ms/step - loss: 3.2478\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 2s 941ms/step - loss: 3.2542\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 2s 932ms/step - loss: 3.2544\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 2s 938ms/step - loss: 3.2534\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 2s 922ms/step - loss: 3.2564\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 2s 927ms/step - loss: 3.2490\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 2s 931ms/step - loss: 3.2555\n",
      "Epoch 163/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 2s 925ms/step - loss: 3.2545\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 2s 934ms/step - loss: 3.2537\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 2s 924ms/step - loss: 3.2531\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 2s 944ms/step - loss: 3.2548\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 2s 940ms/step - loss: 3.2559\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 2s 921ms/step - loss: 3.2528\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 2s 935ms/step - loss: 3.2538\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 2s 931ms/step - loss: 3.2507\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 2s 919ms/step - loss: 3.2524\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 2s 940ms/step - loss: 3.2528\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.2548\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 2s 925ms/step - loss: 3.2528\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 2s 927ms/step - loss: 3.2535\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 2s 1s/step - loss: 3.2512\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 2s 943ms/step - loss: 3.2557\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 2s 956ms/step - loss: 3.2554\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 2s 926ms/step - loss: 3.2552\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 2s 937ms/step - loss: 3.2573\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 2s 928ms/step - loss: 3.2570\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 2s 926ms/step - loss: 3.2525\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 2s 940ms/step - loss: 3.2521\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 2s 933ms/step - loss: 3.2526\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 2s 927ms/step - loss: 3.2555\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 2s 929ms/step - loss: 3.2565\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 2s 918ms/step - loss: 3.2538\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 2s 923ms/step - loss: 3.2567\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 2s 938ms/step - loss: 3.2514\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 2s 924ms/step - loss: 3.2524\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 2s 926ms/step - loss: 3.2518\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 2s 929ms/step - loss: 3.2526\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 2s 930ms/step - loss: 3.2546\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 2s 929ms/step - loss: 3.2565\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 2s 919ms/step - loss: 3.2538\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 2s 920ms/step - loss: 3.2496\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 2s 925ms/step - loss: 3.2526\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 2s 930ms/step - loss: 3.2523\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 2s 925ms/step - loss: 3.2549\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 2s 937ms/step - loss: 3.2548\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc26c319ac0>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Более глубокая сеть что-то совсем не хочет учиться "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "model.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Виктор                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         '"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, start_string=u\"Виктор \", temperature=0.01, num_generate=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Краткость - сестра таланта )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Виктор                                                                                                                                                                                                                                                                                                                                                                                о                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        '"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, start_string=u\"Виктор \", temperature=0.1, num_generate=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(128),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = build_model(\n",
    "    vocab_size=len(vocab),\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints3'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    period=20,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 3s 453ms/step - loss: 4.2740\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 1s 449ms/step - loss: 6.2365\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 1s 448ms/step - loss: 4.3346\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 1s 452ms/step - loss: 4.1694\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 1s 448ms/step - loss: 3.8827\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 1s 471ms/step - loss: 3.5866\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 3.3724\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 1s 449ms/step - loss: 3.3486\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 1s 449ms/step - loss: 3.3124\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 3.3022\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 1s 449ms/step - loss: 3.2833\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 1s 453ms/step - loss: 3.2899\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 1s 449ms/step - loss: 3.2726\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 1s 445ms/step - loss: 3.2725\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 1s 452ms/step - loss: 3.2644\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 1s 451ms/step - loss: 3.2595\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 3.2633\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 3.2561\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 1s 448ms/step - loss: 3.2580\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 1s 452ms/step - loss: 3.2604\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 1s 477ms/step - loss: 3.2549\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 1s 451ms/step - loss: 3.2559\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 1s 448ms/step - loss: 3.2545\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 1s 454ms/step - loss: 3.2513\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 1s 452ms/step - loss: 3.2542\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 1s 450ms/step - loss: 3.2493\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 1s 513ms/step - loss: 3.2514\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 1s 450ms/step - loss: 3.2485\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 1s 452ms/step - loss: 3.2502\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 3.2494\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 1s 453ms/step - loss: 3.2463\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 3.2432\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 1s 447ms/step - loss: 3.2445\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 1s 454ms/step - loss: 3.2424\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 3.2408\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 1s 453ms/step - loss: 3.2302\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 3.2317\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 3.2283\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 1s 456ms/step - loss: 3.2270\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 3.2160\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 3.2126\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 1s 454ms/step - loss: 3.2046\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 3.2017\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 1s 453ms/step - loss: 3.1937\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 3.1878\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 3.1811\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 3.1750\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 1s 494ms/step - loss: 3.1698\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 1s 454ms/step - loss: 3.1541\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 3.1466\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 3.1439\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 3.1370\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 3.1764\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 3.1561\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 1s 477ms/step - loss: 3.1291\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 1s 586ms/step - loss: 3.1243\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 1s 589ms/step - loss: 3.1088\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 1s 515ms/step - loss: 3.0911\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 1s 452ms/step - loss: 3.0773\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 3.0573\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 3.0423\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 1s 471ms/step - loss: 3.0267\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 3.0073\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 2.9969\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 2.9809\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 2.9596\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 2.9478\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 2.9312\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 1s 472ms/step - loss: 2.9091\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 1s 478ms/step - loss: 2.8978\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 1s 581ms/step - loss: 2.8826\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 1s 471ms/step - loss: 2.8621\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 2.8664\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 1s 555ms/step - loss: 2.9364\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 2.8807\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 2.8476\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 2.8456\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 2.8164\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 2.8023\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 2.7844\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 2.7763\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 2.7657\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 1s 473ms/step - loss: 2.7499\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 2.7353\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 2.7280\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 2.7169\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 2.7058\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 2.6915\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 2.6752\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 2.6690\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 2.6538\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 2.6407\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 2.6228\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 2.6172\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 1s 539ms/step - loss: 2.6075\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 2.5968\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 2.5844\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 2.5671\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 2.5465\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 2.5405\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 2.5180\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 2.5057\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 2.4886\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 2.4828\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 1s 495ms/step - loss: 2.4674\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 2.4580\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 2.4432\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 2.4345\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 2.4205\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 2.4229\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 2.4582\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 2.4475\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 2.4300\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 1s 471ms/step - loss: 2.4132\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 1s 471ms/step - loss: 2.3976\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 2.3964\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 1s 471ms/step - loss: 2.3891\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 1s 474ms/step - loss: 2.3680\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 2.3693\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 2.3382\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 1s 474ms/step - loss: 2.3352\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 1s 481ms/step - loss: 2.3138\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 1s 474ms/step - loss: 2.3207\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 2.3117\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 1s 478ms/step - loss: 2.2895\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 2.2769\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 2.2681\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 2.2634\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 1s 444ms/step - loss: 2.2996\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 2.2826\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 1s 489ms/step - loss: 2.2865\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 2.2478\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 2.2307\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 2.2247\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 1s 473ms/step - loss: 2.2202\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 2.2033\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 2.1945\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 2.1740\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 2.1768\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 2.1635\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 2.1476\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 2.1239\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 2.1264\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 2.1024\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 1s 478ms/step - loss: 2.0948\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 1s 472ms/step - loss: 2.0908\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 1s 471ms/step - loss: 2.0872\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 2.0886\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 2.0601\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 2.0417\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 2.0273\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 2.0084\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 2.0000\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 1.9881\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 1.9934\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 1.9689\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 1.9468\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 1.9172\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 1.9127\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 1s 473ms/step - loss: 1.8974\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 1s 480ms/step - loss: 1.9025\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 1s 472ms/step - loss: 1.8844\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 1.8946\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 1.8661\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 1.8370\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 1.8095\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 1s 471ms/step - loss: 1.7862\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 1.7647\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 1.7296\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 1.7146\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 1.7064\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 1.7727\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 1.8245\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 1.7506\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 1.7355\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 1.7105\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 1.6566\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 1.6291\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 1.5867\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 1.5532\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 1.5066\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 1.4608\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 1.4362\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 1.4036\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 1.4627\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 1.4185\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 1.3896\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 1s 490ms/step - loss: 1.3161\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 1.2923\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 1.2409\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 1.2061\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 1.1578\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 1.2358\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 1.2891\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 1s 472ms/step - loss: 1.2227\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 1.1799\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 1.1198\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 1.1450\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 1s 472ms/step - loss: 1.0545\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 0.9932\n"
     ]
    }
   ],
   "source": [
    "history = model3.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc26b8ec220>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Надо продолжить.. только все началось похоже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 1s 450ms/step - loss: 0.9132\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 1s 454ms/step - loss: 0.8455\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 1s 454ms/step - loss: 0.8028\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 0.7455\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 1s 515ms/step - loss: 0.6906\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 1s 448ms/step - loss: 0.6382\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.5927\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 0.5584\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 0.5404\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 1s 452ms/step - loss: 0.5052\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 1s 452ms/step - loss: 0.6061\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 1s 545ms/step - loss: 0.7380\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.7131\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.6618\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 1s 454ms/step - loss: 0.5890\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.5245\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 1s 454ms/step - loss: 0.4648\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 0.4207\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 1s 472ms/step - loss: 0.3760\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.3415\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 1s 452ms/step - loss: 0.3079\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.2814\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 0.2493\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 1s 449ms/step - loss: 0.2331\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 1s 456ms/step - loss: 0.2188\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 0.1972\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.1874\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 1s 452ms/step - loss: 0.1742\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.1659\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 0.1552\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.1498\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.1425\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 1s 454ms/step - loss: 0.1357\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.1303\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 0.1227\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 0.1197\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.1171\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 1s 456ms/step - loss: 0.1124\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.1072\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 1s 456ms/step - loss: 0.1080\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 0.1012\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.1025\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 0.0993\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0967\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.0947\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 1s 456ms/step - loss: 0.0945\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 1s 475ms/step - loss: 0.0916\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.0884\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.0840\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0869\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.0824\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.0832\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.0826\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0802\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.0786\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 0.0795\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.0750\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0733\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.0748\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0724\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 0.0730\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0709\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0707\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.0704\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0685\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.0691\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 0.0683\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 1s 574ms/step - loss: 0.0679\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.0636\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0652\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.0648\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 0.0653\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.0640\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 1s 481ms/step - loss: 0.0605\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.0603\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0613\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0598\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.0576\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0589\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.0577\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0602\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0567\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.0561\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0540\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.0570\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0539\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.0534\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0564\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0528\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0519\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 0.0492\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 1s 456ms/step - loss: 0.0532\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0486\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 0.0485\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0494\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0501\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0491\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 0.0485\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 0.0474\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 1s 524ms/step - loss: 0.0462\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0465\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0476\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0461\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.0467\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0471\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0426\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.0454\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.0455\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 1s 453ms/step - loss: 0.0445\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0436\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.0427\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.0429\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0433\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0439\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0438\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0414\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.0411\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.0413\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0415\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 0.0415\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0397\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0400\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0411\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 0.0412\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0410\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 1s 456ms/step - loss: 0.0379\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0382\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.0404\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.0390\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.0351\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 0.0389\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0358\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 1s 471ms/step - loss: 0.0374\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 0.0387\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 1s 444ms/step - loss: 0.0382\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 0.0363\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0367\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0346\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 0.0355\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.0350\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0346\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 0.0363\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0341\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0350\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 0.0352\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.0347\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.0362\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.0343\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0343\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 0.0340\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 0.0319\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0340\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0332\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.0334\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.0327\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 0.0330\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.0325\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.0334\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.0316\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 0.0333\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.0311\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 0.0314\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 0.0306\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 1s 508ms/step - loss: 0.0307\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.0328\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 0.0315\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 1s 471ms/step - loss: 0.0316\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0306\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.0318\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 1s 476ms/step - loss: 0.0317\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.0300\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 0.0296\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 1s 476ms/step - loss: 0.0316\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.0292\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 0.0309\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 0.0284\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 1s 471ms/step - loss: 0.0287\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0286\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0286\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.0290\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 0.0288\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0278\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 1s 471ms/step - loss: 0.0274\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0302\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0297\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0281\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0278\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 1s 471ms/step - loss: 0.0278\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.0282\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0279\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.0272\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.0282\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 0.0273\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 0.0287\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 1s 472ms/step - loss: 0.0276\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 0.0260\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.0255\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 0.0272\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0264\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 0.0269\n"
     ]
    }
   ],
   "source": [
    "history = model3.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc26b86ba90>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Можно наверное еще один заход сделать.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 1s 450ms/step - loss: 0.0266\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 1s 448ms/step - loss: 0.0261\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 0.0257\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 0.0254\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 0.0255\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 1s 450ms/step - loss: 0.0253\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 0.0256\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 1s 435ms/step - loss: 0.0271\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 1s 449ms/step - loss: 0.0267\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.0250\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 1s 448ms/step - loss: 0.0247\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.0249\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 1s 451ms/step - loss: 0.0246\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 1s 452ms/step - loss: 0.0247\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.0253\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.0252\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.0239\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.0258\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 1s 449ms/step - loss: 0.0249\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 1s 443ms/step - loss: 0.0236\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 1s 454ms/step - loss: 0.0229\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 0.0238\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 0.0246\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 1s 453ms/step - loss: 0.0240\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 1s 454ms/step - loss: 0.0246\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 0.0229\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 1s 540ms/step - loss: 0.0226\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 1s 549ms/step - loss: 0.0224\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0233\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 0.0221\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 1s 456ms/step - loss: 0.0230\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0221\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.0242\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.0238\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.0226\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 0.0239\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0217\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 0.0216\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.0241\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.0211\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 0.0213\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0229\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.0225\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.0209\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0224\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0222\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.0222\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 1s 454ms/step - loss: 0.0215\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0208\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 0.0213\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 1s 452ms/step - loss: 0.0223\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.0206\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0209\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0210\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 0.0232\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0212\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 1s 569ms/step - loss: 0.0202\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0215\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 1s 477ms/step - loss: 0.0195\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 1s 450ms/step - loss: 0.0223\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.0197\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.0218\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.0206\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.0209\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 0.0203\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 1s 452ms/step - loss: 0.0201\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.0198\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0191\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 1s 515ms/step - loss: 0.0208\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0206\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0201\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0199\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.0207\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0202\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.0199\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.0200\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 0.0191\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0195\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0197\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0197\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0193\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 0.0193\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 1s 482ms/step - loss: 0.0196\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0189\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.0190\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 1s 451ms/step - loss: 0.0200\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0190\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0186\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0192\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.0179\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.0186\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.0184\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.0181\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 1s 493ms/step - loss: 0.0175\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.0182\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0176\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0175\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0187\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 1s 471ms/step - loss: 0.0184\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 0.0177\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.0187\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0173\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.0183\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 0.0184\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0177\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.0172\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0185\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.0177\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0191\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 1s 472ms/step - loss: 0.0182\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 1s 498ms/step - loss: 0.0181\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.0171\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0174\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 0.0180\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 0.0171\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0171\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.0163\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.0174\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 1s 471ms/step - loss: 0.0178\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 1s 498ms/step - loss: 0.0180\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 0.0154\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0169\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0165\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0158\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0165\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 0.0184\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0169\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0161\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 0.0174\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.0163\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.0163\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0166\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 1s 475ms/step - loss: 0.0163\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.0170\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.0170\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0169\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 0.0164\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0154\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.0167\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.0168\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 0.0173\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0169\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.0149\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.0166\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 0.0162\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.0163\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0165\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 0.0153\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 0.0157\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 1s 490ms/step - loss: 0.0156\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 0.0155\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.0147\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0155\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0148\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0148\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.0153\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 0.0151\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 0.0153\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0154\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 0.0149\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0157\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0150\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 0.0147\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0153\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 0.0148\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0147\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.0148\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 1s 474ms/step - loss: 0.0153\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0159\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 1s 482ms/step - loss: 0.0150\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 1s 476ms/step - loss: 0.0144\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.0149\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 0.0145\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0142\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.0140\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0145\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 1s 473ms/step - loss: 0.0148\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.0153\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0147\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0140\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 1s 479ms/step - loss: 0.0150\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.0146\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 0.0139\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 0.0143\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 0.0140\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 0.0146\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 1s 445ms/step - loss: 0.0145\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0148\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 1s 477ms/step - loss: 0.0142\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 0.0136\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 0.0142\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 0.0144\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 1s 473ms/step - loss: 0.0147\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 0.0149\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 1s 473ms/step - loss: 0.0144\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0132\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0131\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 1s 471ms/step - loss: 0.0135\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0142\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 0.0143\n"
     ]
    }
   ],
   "source": [
    "history = model3.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc26822feb0>]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Даже еще до сих пор понижается loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0136\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.0134\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 1s 452ms/step - loss: 0.0141\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 1s 451ms/step - loss: 0.0137\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.0132\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 1s 451ms/step - loss: 0.0136\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 1s 456ms/step - loss: 0.0137\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 0.0154\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 1s 450ms/step - loss: 0.0126\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 1s 453ms/step - loss: 0.0144\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 0.0141\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 0.0137\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 1s 456ms/step - loss: 0.0146\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 1s 454ms/step - loss: 0.0131\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 0.0129\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.0136\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 1s 454ms/step - loss: 0.0133\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 1s 454ms/step - loss: 0.0137\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 0.0122\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.0133\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 1s 453ms/step - loss: 0.0124\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 1s 456ms/step - loss: 0.0134\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 1s 451ms/step - loss: 0.0125\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 0.0134\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0124\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.0136\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 0.0128\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 0.0125\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 0.0130\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 1s 451ms/step - loss: 0.0121\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 0.0132\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 0.0130\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 0.0129\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 0.0118\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 0.0129\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 1s 456ms/step - loss: 0.0127\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 0.0131\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.0119\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0114\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 0.0129\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 1s 455ms/step - loss: 0.0124\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.0122\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 1s 475ms/step - loss: 0.0126\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 1s 452ms/step - loss: 0.0119\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.0130\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 0.0132\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0127\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 0.0126\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0124\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0131\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 0.0124\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.0125\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0122\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0126\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 1s 487ms/step - loss: 0.0130\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 1s 511ms/step - loss: 0.0118\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 0.0123\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0131\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 0.0118\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.0117\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0116\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0119\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0118\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 1s 564ms/step - loss: 0.0124\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 1s 562ms/step - loss: 0.0116\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 1s 485ms/step - loss: 0.0128\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 1s 477ms/step - loss: 0.0121\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 1s 480ms/step - loss: 0.0114\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 1s 471ms/step - loss: 0.0124\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0114\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0121\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 1s 457ms/step - loss: 0.0120\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.0129\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 0.0113\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 0.0114\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 0.0130\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 0.0117\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.0120\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 1s 538ms/step - loss: 0.0112\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 1s 545ms/step - loss: 0.0124\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 1s 580ms/step - loss: 0.0126\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 0.6167\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 6.9122\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 1s 588ms/step - loss: 9.7097\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 1s 490ms/step - loss: 8.5127\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 1s 510ms/step - loss: 6.0917\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 4.3043\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 1s 496ms/step - loss: 3.7228\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 3.3701\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 3.3131\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 1s 504ms/step - loss: 3.2956\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 3.2682\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 1s 471ms/step - loss: 3.2309\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 3.1925\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 3.1581\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 3.1170\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 3.0797\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 3.0425\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 1s 444ms/step - loss: 3.0094\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 2.9917\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 2.9645\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 2.9508\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 2.9296\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 2.9136\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 2.9196\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 2.8970\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 2.8810\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 2.8669\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 2.8463\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 2.8301\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 2.8137\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 2.7969\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 2.7828\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 2.7690\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 2.7556\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 2.7420\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 2.7241\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 1s 481ms/step - loss: 2.7155\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 2.6956\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 2.6869\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 2.6656\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 2.6484\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 2.6545\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 2.6785\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 2.6436\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 2.6306\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 2.6101\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 1s 480ms/step - loss: 2.5995\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 2.5878\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 2.5762\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 2.5605\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 2.5538\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 2.5405\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 2.5298\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 2.5196\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 1s 475ms/step - loss: 2.5138\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 2.5116\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 1s 474ms/step - loss: 2.4941\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 2.4865\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 1s 512ms/step - loss: 2.4775\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 1s 483ms/step - loss: 2.4805\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 1s 475ms/step - loss: 2.4783\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 1s 466ms/step - loss: 2.4605\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 2.4605\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 1s 484ms/step - loss: 2.4443\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 2.4391\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 1s 472ms/step - loss: 2.4310\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 2.4250\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 2.4177\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 2.4063\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 2.4023\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 1s 476ms/step - loss: 2.3948\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 1s 471ms/step - loss: 2.3946\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 1s 470ms/step - loss: 2.4023\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 1s 484ms/step - loss: 2.3939\n",
      "Epoch 156/200\n",
      "2/2 [==============================] - 1s 499ms/step - loss: 2.3843\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 1s 560ms/step - loss: 2.3705\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 1s 550ms/step - loss: 2.3620\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 1s 561ms/step - loss: 2.3505\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 2.3487\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 1s 478ms/step - loss: 2.3387\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 2.3356\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 1s 471ms/step - loss: 2.3592\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 2.3600\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 2.3522\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 2.3274\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 2.3241\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 2.3142\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 2.3125\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 2.3039\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 2.2921\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 2.2886\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 2.2854\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 2.2727\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 2.2693\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 1s 465ms/step - loss: 2.2625\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 2.2511\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 2.2552\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 1s 471ms/step - loss: 2.2426\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 2.2453\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 1s 469ms/step - loss: 2.2336\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 1s 568ms/step - loss: 2.2300\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 1s 508ms/step - loss: 2.2681\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 2.2458\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 1s 462ms/step - loss: 2.2281\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 1s 464ms/step - loss: 2.2219\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 1s 499ms/step - loss: 2.2074\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 1s 481ms/step - loss: 2.2088\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 1s 467ms/step - loss: 2.2050\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 1s 468ms/step - loss: 2.1949\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 1s 461ms/step - loss: 2.1842\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 1s 478ms/step - loss: 2.1874\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 1s 471ms/step - loss: 2.1810\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 1s 472ms/step - loss: 2.1697\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 1s 483ms/step - loss: 2.1626\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 1s 583ms/step - loss: 2.1624\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 1s 550ms/step - loss: 2.1831\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 1s 460ms/step - loss: 2.1886\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 1s 463ms/step - loss: 2.1537\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 1s 472ms/step - loss: 2.1538\n"
     ]
    }
   ],
   "source": [
    "history = model3.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc2682901c0>]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Так, ну тут мы снижались до 79 эпохи.. суммарно мы учим уже 679 эпох.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model3.load_weights('./training_checkpoints3/ckpt_60')\n",
    "model3.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ирмана и нибрала номер.-  Его нет, - сказала она. - Нет-нет, он ушел… Я тоже… Ничего, ничего, что вы… Спокойной ночи.Она положила трубку, постояла немного, смотря в темноту за окном, затем села на кровать рядом с Виктором. В руке у нее был цилиндрический фонарик. Виктор закурил сигарету и подал ей. Она молча курила, о чем-то напряженно думая, а потом спросила:-  Ты когда заснул?-  Не знаю, трудно сказать.-  Но уже после меня?-  Да.Она повернула к нему лицо.-  Ты ничего не слышал? Какого-нибудь скатал, что Диана - женщина с тайной. С первого взгляда и все пять дней… Ну и сырость, надо было глотнуть перед уходом. Как только вернусь, сейчас же глотну… А я молодец, подумал он. Никаких вопросов. Слушаюсь и повинуюсь.Они обошли крыльцо, пробрались через сирень и оказались перед оградой. Диана посветила. Одного железного прута в ограде не было.-  Виктор, - сказала она негромко. - Сейчас мы пойдем по тропинке. Ты пойдешь сзади. Смотри под ноги, и ни шагу в сторону. Понял?-  Понял, - покорно сказал мальчик.-  Вот и хорошо. Не надо никого звать и не надо никому говорить а давай-ка немножко посидим и опомнимся.Теперь он разглядел, что с Бол-Кунацем тоже не все в порядке, на щеке у него темнела свежая царапина, а верхняя губа припухла и кровоточила-  Я все-таки позову кого-нибудь, - сказал Бол-Кунац.-  Стоит ли?-  Видите ли, господин Банев, мне не нравится, как у вас дергается лицо.-  В самом деле? - Виктор ощупал лицо. Лицо не дергалось… - Это тебе только кажется… А теперь мы встанем. Чтох ничету у мал его стровола шла к подъезду.-  Пока в вестибюль, - ответила Диана.-  Не надо, - тем же напряженным голосом произнес мокрец. - Оставьте меня здесь.-  Здесь дождь, - возразил Виктор.-  Перестаньте болтать, - сказал мокрец. - Я останусь здесь.Виктор промолчал и стал подниматься по ступенькам.-  Оставь его, - сказала Диана.Виктор остановился.-  Какого черта, - сказал он. - Здесь же дождь.-  Не будьте дураком, - повторил мокрец. - Оставьте… здесь…Виктор, не говоря ни слова, шагая через т'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model3, start_string=u\"Ирма\", temperature=0.3, num_generate=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ну вобщем довольно сносно цитирует )) наверное технически это нельзя считать переобучением..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ирмать и вообще прикасаться… Мы их все боялись, как заразы.-  Я же говорю вам: это генетическая болезнь, - сказал Голем. - Она абсолютно не заразная.-  Как же не заразная, - возразил Виктор, - когда от нее бородавки, как от жабы! Это все знают.-  От жаб не бывает бородавок, - благодушно сказал Голем. - От мокрецов тоже. Стыдно, что ог Тэдди мезу.-  Дачай тоберю привить?-  Резятевпоету, - сказал Виктор. Он выпетил ун у был отузался ш бростиный мело. - Сначал мостец. И я виновет, но будет не госодис, а виде сам вос садаренял. Потому что это дуратька. Не потохнулся, кры ни приемазитесь, казался он все ожидал, у ту у нах окромонивелисто, - нобее начего васетащищься и понявыесь в ажломь никамо хольшы. В перем не я.-  Голема, - сказал Виктор.-  Жаль, сказал Голем. - Впрочем, желаю удачи.-  Привет Росшеперу, - сказал, поднялся и терьу и потянется. Напреви поркоги он остановился и неферам моррекувать, станавась держать Законнаю мьче, они не глачилось к черныйск-питам, зоговодо не ная, а настеть стизый со Всвы драга ещ обызыех редостана.-  Сколько тебе лет? - спросил он.-  Четырнадцать, - рассеяно ответил Бол-Кунац.-  АСакил… - Он свул был Виктор. - Хватит.-  Мне показалось, - сказал мальчик серьезно, - что вы еще не очнулись.Виктор осторожно засунул руку под капюшон и ощупал затылок. Там была шишка - никаких раздробленных костей, даже крови не было.-  Кто же это меня? - задумчиво спросил он. - Надеюсь, не ты?-  Вы сможете идти, господин Банев? - сказал мальчик. - Или позвать кого-нибудь? Видите ли, для меня вы слишком тяжелый.Виктор вспомнил, кто это.-  Я тебя знаю, - сказал он. - Ты - Бол-Кунац, приятель моей дочери.-  Да, - сказал микриговным нучный, а от блиный расскавдиль Дианес пелевесте ерезнеченены. Он онизвидул суберк столлно свяльовиль, кратные пятна пропалить и вественул но с бледный модась бостоный солодны, потоку у теля на дресть. Трекин был весь зазычал ум нерепоноги и втруг у быле поверил бо карепорь и наха о был везоставовьси, - свворил долшепри. - Я отецусь, не '"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model3, start_string=u\"Ирма\", temperature=1, num_generate=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Далее попробуем построить эту штуку на словах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Когда Ирма вышла, аккуратно притворив за собой дверь, длинноногая, по-взрослому вежливо улыбаясь большим ртом с яркими, как у матери, губами, Виктор принялся старательно раскуривать сигарету. Это не ребенок, думал он ошеломленно. Дети так не говорят. Это даже не грубость, - это жестокость, и даже не жестокость, а просто ей все равно. Как будто она нам тут теорему доказала, просчитала все, проанализировала, деловито сообщила результат и удалилась, подрагивая косичками, совершенно спокойная. Превозмогая неловкость, Виктор посмотрел на Лолу. Лицо ее шло красными пятнами, яркие губы дрожали, словно она собиралась заплакать, но она, конечно, не думала плакать, она была в бешенстве.-  Ты видишь? - сказала она высоким голосом. - Девчонка, соплячка… Дрянь! Ничего святого, что ни слово-то оскорбление, словно я не мать, а половая тряпка, о которую можно вытирать ноги. Перед соседкой стыдно! Мерзавка, хамка…Да, подумал Виктор, и с этой женщиной я жил. Я гулял с нею в горах, я читал ей Бодлера, и '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/postas/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_text = word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Когда',\n",
       " 'Ирма',\n",
       " 'вышла',\n",
       " ',',\n",
       " 'аккуратно',\n",
       " 'притворив',\n",
       " 'за',\n",
       " 'собой',\n",
       " 'дверь',\n",
       " ',']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_text[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_vocab = sorted(set(tokenized_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4290"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Уникальных слов-то побольше будет - чем уникальных букв"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a mapping from unique words to indices\n",
    "word2idx = {u:i for i, u in enumerate(words_vocab)}\n",
    "idx2word = np.array(words_vocab)\n",
    "\n",
    "words_text_as_int = np.array([word2idx[c] for c in tokenized_text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Когда\n",
      "Ирма\n",
      "вышла\n",
      ",\n",
      "аккуратно\n",
      "притворив\n",
      "за\n",
      "собой\n",
      "дверь\n",
      ",\n"
     ]
    }
   ],
   "source": [
    "# The maximum length sentence you want for a single input in characters\n",
    "seq_length = 100\n",
    "examples_per_epoch = len(tokenized_text)//(seq_length+1)\n",
    "\n",
    "# Create training examples / targets\n",
    "word_dataset = tf.data.Dataset.from_tensor_slices(words_text_as_int)\n",
    "\n",
    "for i in word_dataset.take(10):\n",
    "    print(idx2word[i.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'КогдаИрмавышла,аккуратнопритворивзасобойдверь,длинноногая,по-взросломувежливоулыбаясьбольшимртомсяркими,какуматери,губами,Викторпринялсястарательнораскуриватьсигарету.Этонеребенок,думалоношеломленно.Детитакнеговорят.Этодаженегрубость,-этожестокость,идаженежестокость,апростоейвсеравно.Какбудтоонанамтуттеоремудоказала,просчиталавсе,проанализировала,деловитосообщиларезультатиудалилась,подрагиваякосичками,совершенноспокойная.Превозмогаянеловкость,ВикторпосмотрелнаЛолу.Лицоеешло'\n",
      "'краснымипятнами,яркиегубыдрожали,словноонасобираласьзаплакать,ноона,конечно,недумалаплакать,онабылавбешенстве.-Тывидишь?-сказалаонавысокимголосом.-Девчонка,соплячка…Дрянь!Ничегосвятого,чтонислово-тооскорбление,словноянемать,аполоваятряпка,окоторуюможновытиратьноги.Передсоседкойстыдно!Мерзавка,хамка…Да,подумалВиктор,исэтойженщинойяжил.Ягулялснеювгорах,ячиталейБодлера,итрепетал,когдаприкасалсякней,'\n",
      "'ипомнилеезапах…Кажетсядажедралсяиз-занее.Досихпорнепонимаю,чтоонадумала,когдаячиталейБодлера?Нет,этопростоудивительно,чтомнеудалосьотнееудрать.Умунепостижимо,икаконаменявыпустила?Наверно,ятожебылнесахар.Наверное,яисейчаснесахар,нотогдаяпилещебольшечемсейчас,иктомужеполагалсебябольшимпоэтом.-Тебе,конечно,недотого,кудатам,-говорилаЛола.-Столичнаяжизнь,всякие'\n",
      "'балерины,артистки…Явсезнаю.Невоображай,чтомыздесьничегонезнаем.Иденьгиконечно,бешеные,илюбовницы,ибесконечныескандалы…Мнеэто,еслихочешьтызнать,безразлично,ятебенемешала,тыжилкакхотел…Вообщееегубитто,чтоонаоченьмногоговорит,вдевицахонабылатихая,молчаливая,таинственная.Естьтакиедевицы,которыеотрождениязнают,каксебянадовести.Оназнала.Вообщетоонаисейчасничего,когдасидит,например,молча,надиване'\n",
      "'ссигаретой,выставивколени…Илизаломитвдругрукузаголовуипотянется.Напровинциальногоадвокатаэтодолжнодействоватьчрезвычайно…Викторпредставилсебеуютныйвечерок,этотстоликпридвинутктомувондивану,бутылка,шампанскоешипитвфужерах,перевязаннаяленточкойкоробкашоколадуисамадвокат,закованныйвкрахмал,галстукбабочкой.Всекакулюдей,ивдругвходитИрма…Кошмар,подумалВиктор.Даонаженесчастнаяженщина…-Тысамдолженпонимать,-говорилаЛола,-чтоделоневденьгах,чтонеденьгисейчасвсерешают.-Она'\n"
     ]
    }
   ],
   "source": [
    "sequences = word_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "\n",
    "for item in sequences.take(5):\n",
    "    print(repr(''.join(idx2word[item.numpy()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(chunk):\n",
    "    input_text = chunk[:-1]\n",
    "    target_text = chunk[1:]\n",
    "    return input_text, target_text\n",
    "\n",
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batch size\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset\n",
    "# (TF data is designed to work with possibly infinite sequences,\n",
    "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
    "# it maintains a buffer in which it shuffles elements).\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in chars\n",
    "vocab_size = len(words_vocab)\n",
    "\n",
    "# The embedding dimension\n",
    "embedding_dim = 1024\n",
    "\n",
    "# Number of RNN units\n",
    "rnn_units = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                  batch_input_shape=[batch_size, None]),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            stateful=True,\n",
    "                            recurrent_initializer='glorot_uniform'),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units,\n",
    "    batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 4290) # (batch_size, sequence_length, vocab_size)\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " 'вундеркинды . Я - отец вундеркинда . Почетно , но хлопотно , и не столько почетно , сколько хлопотно , да в конце концов и не почетно вовсе , а так… А вот эту улочку я всегда любил , потому что она самая узкая . Так , а вот и драка . Правильно , у нас без этого нельзя , мы без этого никак не можем . Это у нас здесь испокон веков . И двое на одного…На углу стоял фонарь . У границы освещенного пространства мокнул автомобиль с брезентовым верхом , а рядом с автомобилем двое в блестящих плащах'\n",
      "\n",
      "Next Word Predictions: \n",
      " 'вздохнул обнял конформистское шее… собой Виктор.Он пусть растворит О нынче положи Без включила подальше пара надвинутых остаются дверях дребезжала безусловно поднял мундир суаре минуту посмотрел заседаниях…- Двое шагу спиной.- площадки бьет каких капало.- вспомнил они скомканные сиянию повинуются… Давай-ка одеяло.- неожиданно подоконник мужественное мол воды.- Напишу раскинул фар бегал хлестала домой.Снова Но прислушался возьми вечерок люблю мальчишка захлопнулись каленым потащила косичками мостовой палате духе надоел…Пора налево студенистое пустыми бумажными вселенной.Если приятель дикие очищенной… редкие пнул воздух небось потерять рвань получить дубинки плакать непонятное пахло До Кастетом… решительно Кошмар рукой… кирпичной меня мне…- щенка Банев встревожился появилась ура беспокою систематический постоянную'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", repr(' '.join(idx2word[input_example_batch[0]])))\n",
    "print()\n",
    "print(\"Next Word Predictions: \\n\", repr(' '.join(idx2word[sampled_indices ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Вобщем тут на необученной сети хотя бы слова нормальные ))) хоть и чушь полная конечно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 4290)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss:       8.364232\n"
     ]
    }
   ],
   "source": [
    "def loss(labels, logits):\n",
    "    return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# Directory where the checkpoints will be saved\n",
    "checkpoint_dir = './training_checkpoints_words1'\n",
    "# Name of the checkpoint files\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    period=20,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 400\n",
    "# Для начала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "2/2 [==============================] - 2s 306ms/step - loss: 8.3533\n",
      "Epoch 2/400\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 7.4651\n",
      "Epoch 3/400\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 7.0304\n",
      "Epoch 4/400\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 6.7109\n",
      "Epoch 5/400\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 6.5588\n",
      "Epoch 6/400\n",
      "2/2 [==============================] - 1s 340ms/step - loss: 6.5468\n",
      "Epoch 7/400\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 6.4927\n",
      "Epoch 8/400\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 6.4688\n",
      "Epoch 9/400\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 6.4623\n",
      "Epoch 10/400\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 6.4438\n",
      "Epoch 11/400\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 6.4267\n",
      "Epoch 12/400\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 6.4478\n",
      "Epoch 13/400\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 6.4372\n",
      "Epoch 14/400\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 6.4354\n",
      "Epoch 15/400\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 6.4414\n",
      "Epoch 16/400\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 6.4283\n",
      "Epoch 17/400\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 6.4428\n",
      "Epoch 18/400\n",
      "2/2 [==============================] - 1s 282ms/step - loss: 6.4082\n",
      "Epoch 19/400\n",
      "2/2 [==============================] - 1s 286ms/step - loss: 6.4127\n",
      "Epoch 20/400\n",
      "2/2 [==============================] - 1s 307ms/step - loss: 6.4022\n",
      "Epoch 21/400\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 6.3912\n",
      "Epoch 22/400\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 6.3868\n",
      "Epoch 23/400\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 6.3109\n",
      "Epoch 24/400\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 6.2991\n",
      "Epoch 25/400\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 6.2451\n",
      "Epoch 26/400\n",
      "2/2 [==============================] - 1s 367ms/step - loss: 6.1913\n",
      "Epoch 27/400\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 6.1129\n",
      "Epoch 28/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 6.0795\n",
      "Epoch 29/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 5.9902\n",
      "Epoch 30/400\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 5.9350\n",
      "Epoch 31/400\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 5.8676\n",
      "Epoch 32/400\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 5.8065\n",
      "Epoch 33/400\n",
      "2/2 [==============================] - 1s 285ms/step - loss: 5.7142\n",
      "Epoch 34/400\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 5.7047\n",
      "Epoch 35/400\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 5.6203\n",
      "Epoch 36/400\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 5.5649\n",
      "Epoch 37/400\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 5.5236\n",
      "Epoch 38/400\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 5.4633\n",
      "Epoch 39/400\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 5.3954\n",
      "Epoch 40/400\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 5.3440\n",
      "Epoch 41/400\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 5.2957\n",
      "Epoch 42/400\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 5.2312\n",
      "Epoch 43/400\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 5.1745\n",
      "Epoch 44/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 5.1240\n",
      "Epoch 45/400\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 5.0528\n",
      "Epoch 46/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 4.9948\n",
      "Epoch 47/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 4.9300\n",
      "Epoch 48/400\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 4.8683\n",
      "Epoch 49/400\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 4.7859\n",
      "Epoch 50/400\n",
      "2/2 [==============================] - 1s 284ms/step - loss: 4.7382\n",
      "Epoch 51/400\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 4.6627\n",
      "Epoch 52/400\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 4.5823\n",
      "Epoch 53/400\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 4.5299\n",
      "Epoch 54/400\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 4.4732\n",
      "Epoch 55/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 4.4106\n",
      "Epoch 56/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 4.3134\n",
      "Epoch 57/400\n",
      "2/2 [==============================] - 1s 368ms/step - loss: 4.2675\n",
      "Epoch 58/400\n",
      "2/2 [==============================] - 1s 310ms/step - loss: 4.1645\n",
      "Epoch 59/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 4.0987\n",
      "Epoch 60/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 4.0074\n",
      "Epoch 61/400\n",
      "2/2 [==============================] - 1s 310ms/step - loss: 3.9314\n",
      "Epoch 62/400\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 3.8274\n",
      "Epoch 63/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 3.7427\n",
      "Epoch 64/400\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 3.6661\n",
      "Epoch 65/400\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 3.5768\n",
      "Epoch 66/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 3.5204\n",
      "Epoch 67/400\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 3.4102\n",
      "Epoch 68/400\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 3.3457\n",
      "Epoch 69/400\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 3.2483\n",
      "Epoch 70/400\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 3.1565\n",
      "Epoch 71/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 3.0688\n",
      "Epoch 72/400\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 2.9605\n",
      "Epoch 73/400\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 2.8968\n",
      "Epoch 74/400\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 2.8087\n",
      "Epoch 75/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 2.7172\n",
      "Epoch 76/400\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 2.6534\n",
      "Epoch 77/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 2.6111\n",
      "Epoch 78/400\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 2.4935\n",
      "Epoch 79/400\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 2.4316\n",
      "Epoch 80/400\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 2.3492\n",
      "Epoch 81/400\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 2.2711\n",
      "Epoch 82/400\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 2.1877\n",
      "Epoch 83/400\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 2.1303\n",
      "Epoch 84/400\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 2.0436\n",
      "Epoch 85/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 1.9667\n",
      "Epoch 86/400\n",
      "2/2 [==============================] - 1s 307ms/step - loss: 1.8999\n",
      "Epoch 87/400\n",
      "2/2 [==============================] - 1s 309ms/step - loss: 1.8337\n",
      "Epoch 88/400\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 1.7765\n",
      "Epoch 89/400\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 1.7087\n",
      "Epoch 90/400\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 1.6504\n",
      "Epoch 91/400\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 1.5916\n",
      "Epoch 92/400\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 1.5301\n",
      "Epoch 93/400\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 1.4813\n",
      "Epoch 94/400\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 1.4126\n",
      "Epoch 95/400\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 1.3567\n",
      "Epoch 96/400\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 1.3112\n",
      "Epoch 97/400\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 1.2725\n",
      "Epoch 98/400\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 1.2112\n",
      "Epoch 99/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 1.1731\n",
      "Epoch 100/400\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 1.1186\n",
      "Epoch 101/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 1.0788\n",
      "Epoch 102/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 292ms/step - loss: 1.0253\n",
      "Epoch 103/400\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.9941\n",
      "Epoch 104/400\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.9590\n",
      "Epoch 105/400\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.9139\n",
      "Epoch 106/400\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.8791\n",
      "Epoch 107/400\n",
      "2/2 [==============================] - 1s 290ms/step - loss: 0.8410\n",
      "Epoch 108/400\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.7930\n",
      "Epoch 109/400\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.7768\n",
      "Epoch 110/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.7563\n",
      "Epoch 111/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.7081\n",
      "Epoch 112/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.6763\n",
      "Epoch 113/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.6519\n",
      "Epoch 114/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.6226\n",
      "Epoch 115/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.5914\n",
      "Epoch 116/400\n",
      "2/2 [==============================] - 1s 372ms/step - loss: 0.5594\n",
      "Epoch 117/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.5355\n",
      "Epoch 118/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.5100\n",
      "Epoch 119/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.4938\n",
      "Epoch 120/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.4667\n",
      "Epoch 121/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.4414\n",
      "Epoch 122/400\n",
      "2/2 [==============================] - 1s 288ms/step - loss: 0.4241\n",
      "Epoch 123/400\n",
      "2/2 [==============================] - 1s 287ms/step - loss: 0.4091\n",
      "Epoch 124/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.3858\n",
      "Epoch 125/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.3667\n",
      "Epoch 126/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.3534\n",
      "Epoch 127/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.3429\n",
      "Epoch 128/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.3239\n",
      "Epoch 129/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.3181\n",
      "Epoch 130/400\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.3043\n",
      "Epoch 131/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.2851\n",
      "Epoch 132/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.2761\n",
      "Epoch 133/400\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.2576\n",
      "Epoch 134/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.2465\n",
      "Epoch 135/400\n",
      "2/2 [==============================] - 1s 322ms/step - loss: 0.2412\n",
      "Epoch 136/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.2314\n",
      "Epoch 137/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.2241\n",
      "Epoch 138/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.2191\n",
      "Epoch 139/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.2108\n",
      "Epoch 140/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.2054\n",
      "Epoch 141/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.1960\n",
      "Epoch 142/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.1901\n",
      "Epoch 143/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.1889\n",
      "Epoch 144/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.1781\n",
      "Epoch 145/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.1767\n",
      "Epoch 146/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.1708\n",
      "Epoch 147/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.1696\n",
      "Epoch 148/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.1659\n",
      "Epoch 149/400\n",
      "2/2 [==============================] - 1s 308ms/step - loss: 0.1606\n",
      "Epoch 150/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.1546\n",
      "Epoch 151/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.1525\n",
      "Epoch 152/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.1452\n",
      "Epoch 153/400\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.1449\n",
      "Epoch 154/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.1391\n",
      "Epoch 155/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.1413\n",
      "Epoch 156/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.1330\n",
      "Epoch 157/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.1286\n",
      "Epoch 158/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.1290\n",
      "Epoch 159/400\n",
      "2/2 [==============================] - 1s 289ms/step - loss: 0.1236\n",
      "Epoch 160/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.1229\n",
      "Epoch 161/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.1171\n",
      "Epoch 162/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.1184\n",
      "Epoch 163/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.1168\n",
      "Epoch 164/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.1146\n",
      "Epoch 165/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.1120\n",
      "Epoch 166/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.1118\n",
      "Epoch 167/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.1080\n",
      "Epoch 168/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.1079\n",
      "Epoch 169/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.1034\n",
      "Epoch 170/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.1001\n",
      "Epoch 171/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.1007\n",
      "Epoch 172/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0985\n",
      "Epoch 173/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0965\n",
      "Epoch 174/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0973\n",
      "Epoch 175/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0936\n",
      "Epoch 176/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0903\n",
      "Epoch 177/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0919\n",
      "Epoch 178/400\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0845\n",
      "Epoch 179/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0862\n",
      "Epoch 180/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0897\n",
      "Epoch 181/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0874\n",
      "Epoch 182/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0874\n",
      "Epoch 183/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0846\n",
      "Epoch 184/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0856\n",
      "Epoch 185/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0841\n",
      "Epoch 186/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0832\n",
      "Epoch 187/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0809\n",
      "Epoch 188/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0799\n",
      "Epoch 189/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0775\n",
      "Epoch 190/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0753\n",
      "Epoch 191/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0780\n",
      "Epoch 192/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0748\n",
      "Epoch 193/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0756\n",
      "Epoch 194/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0767\n",
      "Epoch 195/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0697\n",
      "Epoch 196/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0720\n",
      "Epoch 197/400\n",
      "2/2 [==============================] - 1s 340ms/step - loss: 0.0695\n",
      "Epoch 198/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0685\n",
      "Epoch 199/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0701\n",
      "Epoch 200/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0704\n",
      "Epoch 201/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0646\n",
      "Epoch 202/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0683\n",
      "Epoch 203/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0654\n",
      "Epoch 204/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0646\n",
      "Epoch 205/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.0657\n",
      "Epoch 206/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0643\n",
      "Epoch 207/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0603\n",
      "Epoch 208/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.0612\n",
      "Epoch 209/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0667\n",
      "Epoch 210/400\n",
      "2/2 [==============================] - 1s 311ms/step - loss: 0.0609\n",
      "Epoch 211/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0585\n",
      "Epoch 212/400\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0584\n",
      "Epoch 213/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0588\n",
      "Epoch 214/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0549\n",
      "Epoch 215/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0594\n",
      "Epoch 216/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0555\n",
      "Epoch 217/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0554\n",
      "Epoch 218/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0545\n",
      "Epoch 219/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0569\n",
      "Epoch 220/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0539\n",
      "Epoch 221/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0531\n",
      "Epoch 222/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0531\n",
      "Epoch 223/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0546\n",
      "Epoch 224/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0557\n",
      "Epoch 225/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0529\n",
      "Epoch 226/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0503\n",
      "Epoch 227/400\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.0511\n",
      "Epoch 228/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0512\n",
      "Epoch 229/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0519\n",
      "Epoch 230/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0516\n",
      "Epoch 231/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0483\n",
      "Epoch 232/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0509\n",
      "Epoch 233/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0472\n",
      "Epoch 234/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0468\n",
      "Epoch 235/400\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0479\n",
      "Epoch 236/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0474\n",
      "Epoch 237/400\n",
      "2/2 [==============================] - 1s 322ms/step - loss: 0.0460\n",
      "Epoch 238/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0473\n",
      "Epoch 239/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0447\n",
      "Epoch 240/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0458\n",
      "Epoch 241/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0456\n",
      "Epoch 242/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0428\n",
      "Epoch 243/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0444\n",
      "Epoch 244/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0456\n",
      "Epoch 245/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.0428\n",
      "Epoch 246/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0452\n",
      "Epoch 247/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.0430\n",
      "Epoch 248/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0422\n",
      "Epoch 249/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0429\n",
      "Epoch 250/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0412\n",
      "Epoch 251/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0419\n",
      "Epoch 252/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0414\n",
      "Epoch 253/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0410\n",
      "Epoch 254/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0400\n",
      "Epoch 255/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0397\n",
      "Epoch 256/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0376\n",
      "Epoch 257/400\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0408\n",
      "Epoch 258/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0377\n",
      "Epoch 259/400\n",
      "2/2 [==============================] - 1s 320ms/step - loss: 0.0382\n",
      "Epoch 260/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0400\n",
      "Epoch 261/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0373\n",
      "Epoch 262/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0384\n",
      "Epoch 263/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0380\n",
      "Epoch 264/400\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0369\n",
      "Epoch 265/400\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0367\n",
      "Epoch 266/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0369\n",
      "Epoch 267/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0377\n",
      "Epoch 268/400\n",
      "2/2 [==============================] - 1s 318ms/step - loss: 0.0379\n",
      "Epoch 269/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0342\n",
      "Epoch 270/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0364\n",
      "Epoch 271/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0357\n",
      "Epoch 272/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0336\n",
      "Epoch 273/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0346\n",
      "Epoch 274/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0336\n",
      "Epoch 275/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0343\n",
      "Epoch 276/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.0355\n",
      "Epoch 277/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.0345\n",
      "Epoch 278/400\n",
      "2/2 [==============================] - 1s 310ms/step - loss: 0.0342\n",
      "Epoch 279/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0312\n",
      "Epoch 280/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0305\n",
      "Epoch 281/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0343\n",
      "Epoch 282/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0335\n",
      "Epoch 283/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0316\n",
      "Epoch 284/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0311\n",
      "Epoch 285/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0321\n",
      "Epoch 286/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0311\n",
      "Epoch 287/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0314\n",
      "Epoch 288/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0311\n",
      "Epoch 289/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0294\n",
      "Epoch 290/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0310\n",
      "Epoch 291/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0291\n",
      "Epoch 292/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0332\n",
      "Epoch 293/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0310\n",
      "Epoch 294/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0304\n",
      "Epoch 295/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0306\n",
      "Epoch 296/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0288\n",
      "Epoch 297/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0288\n",
      "Epoch 298/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.0280\n",
      "Epoch 299/400\n",
      "2/2 [==============================] - 1s 291ms/step - loss: 0.0307\n",
      "Epoch 300/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0296\n",
      "Epoch 301/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0281\n",
      "Epoch 302/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0283\n",
      "Epoch 303/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.0273\n",
      "Epoch 304/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0292\n",
      "Epoch 305/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0312\n",
      "Epoch 306/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0282\n",
      "Epoch 307/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0286\n",
      "Epoch 308/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0277\n",
      "Epoch 309/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0268\n",
      "Epoch 310/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0267\n",
      "Epoch 311/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0272\n",
      "Epoch 312/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0273\n",
      "Epoch 313/400\n",
      "2/2 [==============================] - 1s 292ms/step - loss: 0.0254\n",
      "Epoch 314/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0262\n",
      "Epoch 315/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0256\n",
      "Epoch 316/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0235\n",
      "Epoch 317/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0253\n",
      "Epoch 318/400\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0250\n",
      "Epoch 319/400\n",
      "2/2 [==============================] - 1s 293ms/step - loss: 0.0277\n",
      "Epoch 320/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0255\n",
      "Epoch 321/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0259\n",
      "Epoch 322/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0252\n",
      "Epoch 323/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0248\n",
      "Epoch 324/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0237\n",
      "Epoch 325/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0229\n",
      "Epoch 326/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0251\n",
      "Epoch 327/400\n",
      "2/2 [==============================] - 1s 314ms/step - loss: 0.0232\n",
      "Epoch 328/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0240\n",
      "Epoch 329/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0255\n",
      "Epoch 330/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0242\n",
      "Epoch 331/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0242\n",
      "Epoch 332/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0239\n",
      "Epoch 333/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0227\n",
      "Epoch 334/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0241\n",
      "Epoch 335/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0244\n",
      "Epoch 336/400\n",
      "2/2 [==============================] - 1s 308ms/step - loss: 0.0217\n",
      "Epoch 337/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0232\n",
      "Epoch 338/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0233\n",
      "Epoch 339/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0237\n",
      "Epoch 340/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.0224\n",
      "Epoch 341/400\n",
      "2/2 [==============================] - 1s 303ms/step - loss: 0.0225\n",
      "Epoch 342/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0238\n",
      "Epoch 343/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0232\n",
      "Epoch 344/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0240\n",
      "Epoch 345/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0207\n",
      "Epoch 346/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0218\n",
      "Epoch 347/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0213\n",
      "Epoch 348/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0220\n",
      "Epoch 349/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0208\n",
      "Epoch 350/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0222\n",
      "Epoch 351/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0216\n",
      "Epoch 352/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.0214\n",
      "Epoch 353/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.0203\n",
      "Epoch 354/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0237\n",
      "Epoch 355/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0200\n",
      "Epoch 356/400\n",
      "2/2 [==============================] - 1s 311ms/step - loss: 0.0214\n",
      "Epoch 357/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 0.0209\n",
      "Epoch 358/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0205\n",
      "Epoch 359/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0201\n",
      "Epoch 360/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0213\n",
      "Epoch 361/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0226\n",
      "Epoch 362/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0215\n",
      "Epoch 363/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0213\n",
      "Epoch 364/400\n",
      "2/2 [==============================] - 1s 315ms/step - loss: 0.0224\n",
      "Epoch 365/400\n",
      "2/2 [==============================] - 1s 304ms/step - loss: 0.0192\n",
      "Epoch 366/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0186\n",
      "Epoch 367/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0187\n",
      "Epoch 368/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0208\n",
      "Epoch 369/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0185\n",
      "Epoch 370/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0190\n",
      "Epoch 371/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.0195\n",
      "Epoch 372/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.0210\n",
      "Epoch 373/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0193\n",
      "Epoch 374/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.0190\n",
      "Epoch 375/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0191\n",
      "Epoch 376/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0209\n",
      "Epoch 377/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.0212\n",
      "Epoch 378/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.1092\n",
      "Epoch 379/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 2.5822\n",
      "Epoch 380/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 3.1224\n",
      "Epoch 381/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 2.0250\n",
      "Epoch 382/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 1.5805\n",
      "Epoch 383/400\n",
      "2/2 [==============================] - 1s 305ms/step - loss: 1.2866\n",
      "Epoch 384/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.9733\n",
      "Epoch 385/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.7568\n",
      "Epoch 386/400\n",
      "2/2 [==============================] - 1s 297ms/step - loss: 0.6025\n",
      "Epoch 387/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.4774\n",
      "Epoch 388/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.3858\n",
      "Epoch 389/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.3215\n",
      "Epoch 390/400\n",
      "2/2 [==============================] - 1s 300ms/step - loss: 0.2658\n",
      "Epoch 391/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.2315\n",
      "Epoch 392/400\n",
      "2/2 [==============================] - 1s 295ms/step - loss: 0.1932\n",
      "Epoch 393/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.1758\n",
      "Epoch 394/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.1498\n",
      "Epoch 395/400\n",
      "2/2 [==============================] - 1s 294ms/step - loss: 0.1359\n",
      "Epoch 396/400\n",
      "2/2 [==============================] - 1s 302ms/step - loss: 0.1236\n",
      "Epoch 397/400\n",
      "2/2 [==============================] - 1s 298ms/step - loss: 0.1072\n",
      "Epoch 398/400\n",
      "2/2 [==============================] - 1s 301ms/step - loss: 0.1013\n",
      "Epoch 399/400\n",
      "2/2 [==============================] - 1s 299ms/step - loss: 0.0943\n",
      "Epoch 400/400\n",
      "2/2 [==============================] - 1s 296ms/step - loss: 0.0861\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f38ee621070>]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# До 378 эпохи все было неплохо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_string, temperature=0.0001, num_generate=500):\n",
    "    # Evaluation step (generating text using the learned model)\n",
    "\n",
    "    # Number of characters to generate\n",
    "    # num_generate = 500\n",
    "\n",
    "    # Converting our start string to numbers (vectorizing)\n",
    "    input_eval = [word2idx[s] for s in start_string]\n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "    # Empty string to store our results\n",
    "    text_generated = []\n",
    "\n",
    "    # Low temperature results in more predictable text.\n",
    "    # Higher temperature results in more surprising text.\n",
    "    # Experiment to find the best setting.\n",
    "\n",
    "    # Here batch size == 1\n",
    "    model.reset_states()\n",
    "    for i in range(num_generate):\n",
    "        predictions = model(input_eval)\n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        # using a categorical distribution to predict the word returned by the model\n",
    "        predictions = predictions / temperature\n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "\n",
    "        # Pass the predicted word as the next input to the model\n",
    "        # along with the previous hidden state\n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "        text_generated.append(idx2word[predicted_id])\n",
    "\n",
    "    return (' '.join(start_string) + ' '.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_word = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n",
    "model_word.load_weights('./training_checkpoints_words1/ckpt_360')\n",
    "model_word.build(tf.TensorShape([1, None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Викторнет мечутся показался городом городом показался сказал Виктор . - А то у нас нынче все радикалы . Даже директор гимназии . Консерватизм - это наше спасение.Виктор хлебнул джину и сказал горестно : - Не будет никакого спасения . Потому что все дураки-радикалы не только верят в прогресс , они еще и любят прогресс , они воображают , что не могут без прогресса . Потому что прогресс - это , кроме всего прочего , дешевые автомобили , бытовая электроника и вообще возможность делать поменьше а получать побольше . И потому каждое правительство вынуждено одной рукой… то есть , не рукой , конечно… одной ногой нажимать лежал за углом ? Ты там живешь ? - Видите ли , я лежал , потому что меня ударили еще раньше . Не тот , который вас ударил , а другой.- Очкарик ? Они медленно шли , стараясь держаться мостовой , чтобы на них не лило с крыш.- Н-нет , - ответил Бол-Кунац , подумав . - По-моему , они все были без очков.- О , господи , - сказал Виктор . Он полез рукой под капюшон и потрогал шишку . - Я говорю о прокаженном , их называют очкариками . Ну , знаешь , из лепрозория ? Мокрецы…- Не орите , - сказал мокрец . - Я слышу.- Больно ? - сочувственно спросил Виктор.- А вы как думаете ? На редкость неприятный человек , подумал Виктор . Впрочем , бог с ним . Встретились и разошлись . А ему больно…- Ничего , - сказал он . - Потерпите еще есть , чтобы они все были вполне здоровы , - сдержанно произнес Бол-Кунац.- Ну-ну ! - сказал Виктор . Он ощутил некоторое беспокойство и даже остановился . - Ты что же , хочешь меня уверить , что там не было прокаженного ? С черной повязкой , весь в черном…- Это никакой не прокаженный ! - с неожиданной запальчивостью сказал Бол-Кунац . - Он поздоровее вас…Впервые в этом мальчике обнаружилось что-то мальчишечье и сразу исчезло.- Я не совсем понимаю , куда мы идем , - помолчав , сказал он прежним серьезным до бесстрастия тоном . - Сначала мне показалось , что вы бы от резиновой дубинки ? Как бывает от модернового стула в « Жареном Пегасе » - это я знаю . Как бывает от автоматного приклада , или , например , от рукоятки пистолета , я тоже знаю , от бутылки из под шампанского и от бутылки с шампанским… Надо будет спросить Голема… Вообще странная какая-то история , хорошо бы в ней разобраться… И он стал разбираться в этой истории , чтобы отогнать всплывшую вторым планом мысль об Ирме ее запах… Кажется даже дрался из-за нее . До сих пор не понимаю , что она думала , когда я читал ей Бодлера ? Нет , это просто удивительно , что мне удалось от нее удрать . Уму непостижимо , и как она меня выпустила ? Наверно , я тоже был не сахар . Наверное , я и сейчас не сахар , но тогда я пил'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model_word, start_string=['Виктор'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ну... ошидаемо все слова в порядке. При малой температуре он генерирует цитаты сшивая несколько кусков разного текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Мокрецнет мечутся сел сел видел городом мечутся углом мечутся городом сел запах… Виктор.Мальчик пусть городом городом пусть пусть влево показался разболтанный показался доктор Р. Квадрига . Несколько секунд он стоял , с тяжелым вниманием обозревая ряды пустых столиков , затем лицо его прояснилось , и он , резко качнувшись вперед , устремился к своему месту.- Почему вы их называете мокрецами ? - спросил Виктор . - Что они - мокрыми у вас стали от дождя ? - А почему нет ? - сказал Павор . - Как их , по-вашему , называть ? - Очкариками , - сказал Виктор . - Доброе старое слово . Спокон веков называли их очкариками.Доктор Р. Квадрига приближался . Спереди он был весь мокрый , вероятно , над островерхими крышами - дождь , и дождь заливает горы и равнину , и когда-нибудь он все это смоет , но это случится еще очень нескоро… хотя , если подумать , сейчас ни о чем нельзя говорить , что это случится не скоро . Да , милые мои , давно оно прошло , время , когда будущее было повторением настоящего , а все перемены маячили где-то за далеким горизонтом . Голем прав , нет на свете никакого будущего , оно слилось с настоящим , и теперь не разобрать , где что.- Изнасилован мокрецом ! - сказал Павор злорадно.В дверях не замечаешь ? Виктор привычно напряг воображение . Актер танцует на сцене , все хорошо , все прекрасно , все идет , как надо , без накладок , а дома несчастье… нет , не обязательно несчастье , просто ждут , когда же он вернется , и он тоже ждет , когда же дадут занавес и погасят огни… и даже никакой не актер , а посторонний человек , изображающий актера , который сам играет совсем уже постороннего человека… Неужели Диана не чувствует ? Это же фальшивка , манекен.- Пошли плясать ! - закричала она еще издали.Кто-то преградил ей дорогу , кто-то , Павор , - говорил тот . - Отстаньте вы от меня . Что я еще могу . Отчетность я вам представил . Рапорт вам готов подписать . Хотите жаловаться на военных - жалуйтесь . Хотите жаловаться на меня…- Не хочу я на вас жаловаться , - отвечал Павор , прижимая руки к груди.- Тогда не жалуйтесь.- Тогда не жалуйтесь .. - Ну посоветуйте мне что-нибудь ! Неужели вы ничего мне не можете мне посоветовать ? - Господа , - сказал Виктор . - Скучища . Я пойду.На него не обратили внимания . Он отодвинул стул , поднялся и , чувствуя мы под проку товарищи за несчастью , коллеги . Надо будет с ним поговорить , обменяться опытом . Он , наверное , опытнее… Какая однако концентрация вундеркиндов в моем родном промозглом городишке . Может быть , это от повышенной влажности ? .. Он откинул голову и сморщился от боли . Вот гад , как в бою . Такая она сейчас была - как сон , как бой . Диана , на которую нашло… Вокруг били в ладоши и'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model_word, start_string=['Мокрец'], temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ирма» , что такое шизофрения ? - Да , знаю , - сказал Бол-Кунац.- И ты не боишься ? - Нет.Они подошли к отелю , и Виктор предложил : - Может быть , зайдешь ко мне , обсохнешь ? - Благодарю вас . Я как раз собирался попросить разрешения зайти , во-первых , я должен вам кое-что сказать , а , во-вторых , мне надо поговорить по телефону . Вы разрешите ? Виктор разрешил . Они прошли сквозь вращающуюся дверь мимо швейцара , снявшего перед Виктором фуражку , мимо богатых статуй с электрическим свечами , в совершенно пустой вестибюль , пропитанный ресторанным Росшепера , тяжелый и круглый , как свинцовая лепешка . - Он фар рассеивался в нем и В газетах об этом не писали . В газетах честно и мужественно , с суровой прямотой сообщили , что « беллетрист Банев искренне поблагодарил господина Президента за все замечания и разъяснения , сделанные в ходе беседы » .Странно , как хорошо я все помню . - Он обнаружил , что у него побелели щеки и кончик носа . - Вот таким я тогда был , на такого орать сам бог велел . Он ведь не знал бедняга , что это я не от страха бледнею , а от злости , как Людовик Четырнадцатый… Только не будем махать кулаками после не замечаешь ? Виктор бросил простыню на диван , присел на корточки перед баром и вытащил бутылку и стакан.- Ирма мне много чего говорила , - ответил он довольно мрачно . Он налил это полагал меня здесь ? - Виктор . И есть , я должен . Как честный человек , как отец . И я виноват перед нею.- Что же ты молчишь ? - спросила Лола . - Ты так и собираешься молчать ? - Нет-нет , я слушаю тебя , - поспешно сказал Виктор.- Что ты слушаешь ? Я уже полчаса жду , когда там изволишь разбросанное белье , и , - Будет , - сказал Росшепер . - Я тебе говорю , будет . В связи с заражением атмосферы…- Нравственной ! - вставил директор гимназии . - Нравственной и моральной.- Что ? .. В связи , говорю , с отравлением атмосферы и по причине недостаточности обрыбления прилежащих водоемов… заразу ликвидировать и учредить в отдаленной местности . Годится ? - Дай , я тебя поцелую , - сказал полицмейстер.- Молодец , - сказал бургомистр . - Голова . Дай я тебя тоже…- Ерунда , - сказал Росшепер . - Раз плюнуть… Споем ? Нет , не желаю.- Правильно . По маленькой время доля По вагонах Правильно , - сказал мокрец.- В лужу ? - язвительно и горько спросил Виктор.- Это безразлично… Положите.Виктор осторожно опустил его на керамические плиты крыльца , и мокрец сразу вытянулся , и раскинул руки , правая нога его была неестественно вывернута , огромный лоб в свете сильной ничего за трусами , - произнес Виктор с сомнением . - Ты уверен , что это будет интересно всем ? - Я думаю , да.- Все-таки я пишу не'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model_word, start_string=['Ирма'], temperature=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "### На этом думаю закончим"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
